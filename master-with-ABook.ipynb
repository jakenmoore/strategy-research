{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None \n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "# charting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure the breakout is running the correct file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Definitions\n",
    "#################\n",
    "# Where to read data from\n",
    "s3_bucket    = 'mfx-sagemaker-dev'\n",
    "\n",
    "s3_signal_data_key = \"demo/XAUUSD_20200906-000000_20200918-000000/2020-09-06T22:00:00.183Z-2020-09-18T00:00:00.991Z-Input_CFH-MORGANSTANLEY-JPM-CITADEL-JUMP-STATESTREET-FASTMATCH-HOTSPOT-LMAX-JEFFERIES-XTX-GOLDMAN_SACHS_top5-1.csv.gz\"\n",
    "\n",
    "# %% Set the file names\n",
    "filename_futures_quotes = \"/Volumes/GoogleDrive/Shared drives/data/think_xauusd_20200910_quotes.csv\"\n",
    "filename_futures_trades = \"/Volumes/GoogleDrive/Shared drives/data/think_xauusd_20200907_trades_clients.csv\"\n",
    "\n",
    "# make date the same day as the market data \n",
    "date_filter = '2020-09-07'\n",
    "\n",
    "# Bar size\n",
    "resample_period = '10s'\n",
    "\n",
    "# Chart settings\n",
    "chart_padding_secs = 10\n",
    "\n",
    "# Breakout settings\n",
    "breakout_sigma = 1.0\n",
    "\n",
    "# MR settings\n",
    "mr_sigma = 10\n",
    "\n",
    "# Hedging level\n",
    "hedge_level = 3\n",
    "\n",
    "# Hedger interest to fill time in ms\n",
    "interest_to_fill = 10000\n",
    "\n",
    "# n samples for moving average\n",
    "ma_samples = 3\n",
    "\n",
    "# optimise exits\n",
    "optimise_exit = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Load from S3\n",
    "#################\n",
    "\n",
    "\n",
    "\n",
    "# using S3\n",
    "# signal_tick_data = pd.read_csv('s3://{}/{}'.format(s3_bucket, s3_signal_data_key), index_col='t', parse_dates=['t'])\n",
    "\n",
    "\n",
    "# from Drive\n",
    "signal_tick_data = pd.read_csv(filename_futures_quotes, index_col='t', parse_dates=['t'])\n",
    "\n",
    "signal_tick_data = signal_tick_data.between_time(\"06:00\", \"15:00\")\n",
    "trigger_tick_data = signal_tick_data\n",
    "\n",
    "reval_tick_data = signal_tick_data\n",
    "# Source for tick charts\n",
    "chart_tick_data = reval_tick_data\n",
    "\n",
    "signal_tick_data['spread'] = signal_tick_data['Offer0'] - signal_tick_data['Bid0']\n",
    "reval_tick_data['spread'] = reval_tick_data['Offer0'] - reval_tick_data['Bid0']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Aggregate tick data\n",
    "#################\n",
    "signal_mid_price_series = (signal_tick_data.loc[:, 'Bid0'] + signal_tick_data.loc[:, 'Offer0']) / 2\n",
    "trigger_mid_price_series = (trigger_tick_data.loc[:, 'Bid0'] + trigger_tick_data.loc[:, 'Offer0']) / 2\n",
    "reval_mid_price_series = (reval_tick_data.loc[:, 'Bid0'] + reval_tick_data.loc[:, 'Offer0']) / 2\n",
    "# print(reval_mid_price_series.tail())\n",
    "\n",
    "# reval_mid_price_series['reference_mid'] = signal_mid_price_series.asof(reval_mid_price_series.index)\n",
    "# print(signal_mid_price_series.asof(reval_mid_price_series.index), reval_mid_price_series)\n",
    "bar_sampler = signal_mid_price_series.resample(resample_period)\n",
    "\n",
    "hloc = bar_sampler.ohlc() # **FIXME** First tick in bar not last tick in previous bar?\n",
    "\n",
    "# display(hloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Derived columns\n",
    "#################\n",
    "\n",
    "hloc['o_to_h'] = (hloc['high'] / hloc['open'] - 1)\n",
    "hloc['o_to_l'] = (hloc['low'] / hloc['open'] - 1)\n",
    "hloc['c_to_c'] = hloc['close'].pct_change()\n",
    "\n",
    "hloc['o_to_h_vol'] = hloc['o_to_h'].rolling(ma_samples).std()\n",
    "hloc['o_to_l_vol'] = hloc['o_to_l'].rolling(ma_samples).std()\n",
    "hloc['c_to_c_vol'] = hloc['c_to_c'].rolling(ma_samples).std()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# hloc['6_hr_ma'] = hloc['close'].rolling(6).mean()\n",
    "# hloc['6_hr_ma_sig'] = np.where(hloc['close'].shift(1) > hloc['6_hr_ma'].shift(1), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Trigger check\n",
    "#################\n",
    "\n",
    "def mid_trigger_price (timestamp, where): \n",
    "    index = trigger_mid_price_series[timestamp : timestamp + timestamp.freq].where(where).dropna().first_valid_index()\n",
    "    if index == None :\n",
    "        return None\n",
    "    result = reval_mid_price_series.asof(index)\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def trigger_check(row, high_trigger_col, low_trigger_col, high_side):\n",
    "    \n",
    "    triggers = [\n",
    "        ['High', mid_trigger_price(row.name, lambda price: price.gt(row[high_trigger_col])), \n",
    "                 +high_side, row[high_trigger_col]],\n",
    "        ['Low', mid_trigger_price(row.name, lambda price: price.lt(row[low_trigger_col])),\n",
    "                -high_side, row[low_trigger_col]]\n",
    "    ]\n",
    "    \n",
    "    triggers = [t for t in triggers if t[1] is not None]\n",
    "    \n",
    "    triggers.sort(key=lambda t : t[1])\n",
    "    \n",
    "    if not triggers:\n",
    "        return None\n",
    "    \n",
    "    return triggers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Breakout signals\n",
    "#################\n",
    "\n",
    "hloc['breakout_high_trigger'] = hloc['open'] * (1 + (breakout_sigma * (hloc['o_to_h_vol'].shift(1))))\n",
    "hloc['breakout_low_trigger'] = hloc['open'] * (1 - (breakout_sigma * (hloc['o_to_l_vol'].shift(1))))\n",
    "\n",
    "hloc['breakout_triggered'] = hloc.apply(lambda row: trigger_check(row, 'breakout_high_trigger', 'breakout_low_trigger', 1), axis=1)\n",
    "hloc['breakout_triggered'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Mean reversion signals\n",
    "#################\n",
    "\n",
    "hloc['6_hr_ma'] = hloc['close'].rolling(ma_samples).mean()\n",
    "# hloc['6_hr_ma_sig'] = np.where(hloc['close'].shift(1) > hloc['6_hr_ma'].shift(1), 1, -1)\n",
    "\n",
    "hloc['mr_high_trigger'] = hloc['6_hr_ma'] * (1 + (mr_sigma * (hloc['c_to_c_vol'].shift(1))))\n",
    "hloc['mr_low_trigger'] = hloc['6_hr_ma'] * (1 - (mr_sigma * (hloc['c_to_c_vol'].shift(1))))\n",
    "\n",
    "hloc['mr_triggered'] = hloc.apply(lambda row: trigger_check(row, 'mr_high_trigger', 'mr_low_trigger', -1), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# position\n",
    "hloc_filtered = hloc\n",
    "hloc_filtered['breakout_trade'] = hloc_filtered['breakout_triggered'].map(lambda x: 0 if x is None else x[2])\n",
    "hloc_filtered['breakout_trade_price'] = hloc_filtered['breakout_triggered'].map(lambda x: 0 if x is None else x[1])\n",
    "hloc_filtered['breakout_contra_trade_amount'] = -1 * hloc_filtered['breakout_trade'] * hloc_filtered['breakout_trade_price']\n",
    "\n",
    "hloc_filtered['mr_trade'] = hloc_filtered['mr_triggered'].map(lambda x: 0 if x is None else x[2])\n",
    "hloc_filtered['mr_trade_price'] = hloc_filtered['mr_triggered'].map(lambda x: 0 if x is None else x[1])\n",
    "hloc_filtered['mr_contra_trade_amount'] = -1 * hloc_filtered['mr_trade'] * hloc_filtered['mr_trade_price']\n",
    "hloc_filtered['position'] = hloc_filtered['breakout_trade'].cumsum() + hloc_filtered['mr_trade'].cumsum()\n",
    "\n",
    "stdev = np.std(hloc_filtered['close'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hedge trades\n",
    "hloc_filtered['hedge_trade'] = 0.0\n",
    "hloc_filtered['hedge_price'] = 0.0\n",
    "hedge_trade_sum = 0.0\n",
    "hloc_filtered['hedge_contra_amount'] = 0.0\n",
    "current_position = 0.0\n",
    "keep_position = False\n",
    "i_prev = None\n",
    "n = len(hloc_filtered)\n",
    " \n",
    "for i in hloc_filtered.index:\n",
    "    stay_long, stay_short = False, False\n",
    "    current_position = hloc_filtered.loc[i]['position'] + hedge_trade_sum\n",
    "    \n",
    "    if(optimise_exit) :\n",
    "        if current_position > 0 and (hloc_filtered.loc[i]['close'] > (hloc_filtered.loc[i_prev]['close'] + 2.5 * stdev)):\n",
    "            stay_long = True\n",
    "        if current_position < 0 and (hloc_filtered.loc[i]['close'] < (hloc_filtered.loc[i_prev]['close'] - 2.5 * stdev)):\n",
    "            stay_short = True\n",
    "        keep_position = stay_long or stay_short\n",
    "    \n",
    "    if i_prev and not keep_position and (np.absolute(current_position) >= hedge_level):\n",
    "        hloc_filtered.loc[i,'hedge_trade'] = -1 * current_position\n",
    "        hedge_trade_sum += -1 * current_position\n",
    "        # TODO: Review\n",
    "        hedge_price = hloc_filtered.asof(i + pd.Timedelta(milliseconds=interest_to_fill),\n",
    "                                         subset=['close'])['close']\n",
    "        hloc_filtered.loc[i,'hedge_price'] = hedge_price\n",
    "        hloc_filtered.loc[i,'hedge_contra_amount'] = -1 * hloc_filtered.loc[i,'hedge_trade'] * \\\n",
    "                                                     hloc_filtered.loc[i,'hedge_price']\n",
    "    i_prev = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['hedge_balance'] = hloc_filtered['hedge_trade'].cumsum()\n",
    "hloc_filtered['overall_position'] = hloc_filtered['breakout_trade'].cumsum() + hloc_filtered['mr_trade'].cumsum() + hloc_filtered['hedge_trade'].cumsum()\n",
    "hloc_filtered['overall_contra_position'] = hloc_filtered['breakout_contra_trade_amount'].cumsum() + hloc_filtered['mr_contra_trade_amount'].cumsum() + hloc_filtered['hedge_contra_amount'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pnl\n",
    "hloc_filtered['pnl'] = np.where(hloc_filtered['overall_position'] == 0, hloc_filtered['overall_contra_position'], hloc_filtered['overall_position'] * hloc_filtered['close'] + hloc_filtered['overall_contra_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mr strategy returns\n",
    "hloc_filtered['pnl'].resample(\"60s\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['c_to_c_vol'].resample(\"1T\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['overall_position'].resample(\"1T\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volumes, pnl and yield\n",
    "y = 0\n",
    "breakout_volume = np.abs(hloc_filtered['breakout_trade']).sum()\n",
    "mr_volume = np.abs(hloc_filtered['mr_trade']).sum()\n",
    "hedge_volume = np.abs(hloc_filtered['hedge_trade']).sum()\n",
    "total_volume = breakout_volume + mr_volume + hedge_volume\n",
    "total_pnl = hloc_filtered['pnl'].tail(1)\n",
    "y = total_pnl / total_volume \n",
    "display(breakout_volume, mr_volume, hedge_volume, total_volume, total_pnl, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Flow Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OFI lookback \n",
    "ofi_lookback = 2000\n",
    "ofi_resample = \"10ms\"\n",
    "\n",
    "def ofi(quotes,level):\n",
    "    \"\"\"Returns Order Flow Imbalance for given levels of the orderbook\"\"\"\n",
    "    qdf = quotes.copy()\n",
    "    bid_price_label = 'Bid' + str(level)\n",
    "    offer_price_label = 'Offer' + str(level)\n",
    "    bid_qty_label = 'Bid' +str(level) + 'Qty'\n",
    "    offer_qty_label = 'Offer' + str(level)+'Qty'\n",
    "\n",
    "    qdf['prev_bidprice'] = qdf[bid_price_label].shift()\n",
    "    qdf['prev_bidsize'] = qdf[bid_qty_label].shift()\n",
    "    qdf['prev_askprice'] = qdf[offer_price_label].shift()\n",
    "    qdf['prev_asksize'] = qdf[offer_qty_label].shift()\n",
    "\n",
    "    # Fix any missing/invalid data\n",
    "    qdf.replace([np.inf, np.NINF], np.nan, inplace=True)\n",
    "    qdf.fillna(method=\"ffill\", inplace=True)\n",
    "    qdf.fillna(method=\"bfill\", inplace=True)\n",
    "    \n",
    "    bid_geq = qdf[bid_price_label] >= qdf['prev_bidprice']\n",
    "    bid_leq = qdf[bid_price_label] <= qdf['prev_bidprice']\n",
    "    ask_geq = qdf[offer_price_label] >= qdf['prev_askprice']\n",
    "    ask_leq = qdf[offer_price_label] <= qdf['prev_askprice']\n",
    "    \n",
    "    qdf['ofi'] = np.zeros(len(qdf))\n",
    "    qdf['ofi'].loc[bid_geq] += qdf[bid_qty_label].loc[bid_geq]\n",
    "    qdf['ofi'].loc[bid_leq] -= qdf['prev_bidsize'].loc[bid_leq]\n",
    "    qdf['ofi'].loc[ask_geq] += qdf['prev_asksize'].loc[ask_geq]\n",
    "    qdf['ofi'].loc[ask_leq] -= qdf[offer_qty_label].loc[ask_leq]    \n",
    "    return qdf['ofi']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# OFI using top x levels \n",
    "########################\n",
    "df_all = signal_tick_data.resample(ofi_resample).last().ffill()\n",
    "df_all = df_all\n",
    "\n",
    "df_all[\"Offer0Qty\"] = df_all[\"Offer0Qty\"].astype('float')\n",
    "df_all[\"Offer0\"] = df_all[\"Offer0\"].astype('float')\n",
    "df_all[\"Bid0\"] = df_all[\"Bid0\"].astype('float')\n",
    "df_all[\"Bid0Qty\"] = df_all[\"Bid0Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer1Qty\"] = df_all[\"Offer1Qty\"].astype('float')\n",
    "df_all[\"Offer1\"] = df_all[\"Offer1\"].astype('float')\n",
    "df_all[\"Bid1\"] = df_all[\"Bid1\"].astype('float')\n",
    "df_all[\"Bid1Qty\"] = df_all[\"Bid1Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer2Qty\"] = df_all[\"Offer2Qty\"].astype('float')\n",
    "df_all[\"Offer2\"] = df_all[\"Offer2\"].astype('float')\n",
    "df_all[\"Bid2\"] = df_all[\"Bid2\"].astype('float')\n",
    "df_all[\"Bid2Qty\"] = df_all[\"Bid2Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer3Qty\"] = df_all[\"Offer3Qty\"].astype('float')\n",
    "df_all[\"Offer3\"] = df_all[\"Offer3\"].astype('float')\n",
    "df_all[\"Bid3\"] = df_all[\"Bid3\"].astype('float')\n",
    "df_all[\"Bid3Qty\"] = df_all[\"Bid3Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer4Qty\"] = df_all[\"Offer4Qty\"].astype('float')\n",
    "df_all[\"Offer4\"] = df_all[\"Offer4\"].astype('float')\n",
    "df_all[\"Bid4\"] = df_all[\"Bid4\"].astype('float')\n",
    "df_all[\"Bid4Qty\"] = df_all[\"Bid4Qty\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFI with levels 1, 2 and 3 (works better than 0,1,2)\n",
    "# 100 period MA works well\n",
    "\n",
    "df_all = df_all #.resample(ofi_resample).last().ffill()\n",
    "df_all['ofi'] = ofi(df_all,1) + ofi(df_all,2) + ofi(df_all,3) \n",
    "\n",
    "df_all[\"ofi_rolling\"] = df_all['ofi'].rolling(ofi_lookback).mean()\n",
    "df_all['ofi_signal'] = np.where(df_all['ofi_rolling'] > 0, 1, -1)\n",
    "df_all['mid'] = ((df_all['Bid0'] + df_all['Offer0']) / 2.0)\n",
    "df_all['mid_change'] = ((df_all['Bid0'] + df_all['Offer0']) / 2.0).pct_change()\n",
    "\n",
    "\n",
    "# shift the signal\n",
    "df_all['ofi_signal'] = df_all['ofi_signal'].shift(1)\n",
    "df_all['ofi_pnl'] = (df_all['ofi_signal'] * df_all['mid_change'])\n",
    "\n",
    "print(\"Cumulative PnL \" + str(df_all['ofi_pnl'].cumsum().iloc[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_pnl'].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Weighted Mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Volume Weighted Mids\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CWM\n",
    "df_all['weighted_bid_notional_5'] =  df_all[\"Bid1Qty\"] + df_all[\"Bid2Qty\"] + df_all[\"Bid3Qty\"] + df_all[\"Bid4Qty\"]\n",
    "df_all['weighted_offer_notional_5'] =  df_all[\"Offer1Qty\"] + df_all[\"Offer2Qty\"] + df_all[\"Offer3Qty\"] + df_all[\"Offer4Qty\"]\n",
    "df_all['weighted_bid_5'] = (df_all[\"Bid1Qty\"] * df_all[\"Bid1\"] + df_all[\"Bid2Qty\"] * df_all[\"Bid2\"] + df_all[\"Bid3Qty\"] * df_all[\"Bid3\"] + df_all[\"Bid4Qty\"] * df_all[\"Bid4\"]) / df_all['weighted_bid_notional_5'] \n",
    "df_all['weighted_offer_5'] = ( df_all[\"Offer1Qty\"] * df_all[\"Offer1\"] + df_all[\"Offer2Qty\"] * df_all[\"Offer2\"] + df_all[\"Offer3Qty\"] * df_all[\"Offer3\"] + df_all[\"Offer4Qty\"] * df_all[\"Offer4\"]) / df_all['weighted_offer_notional_5'] \n",
    "df_all['conventionally_weighted_mid_5'] = (df_all['weighted_bid_5'] + df_all['weighted_offer_5']) / 2\n",
    "df_all['cwm'] = df_all['conventionally_weighted_mid_5']\n",
    "df_all['cwm_signal'] = np.where(df_all['cwm'] >= df_all['mid'], 1, -1)\n",
    "\n",
    "\n",
    "# slow down to XTX pace \n",
    "df_all['cwm_signal_slow'] = df_all['cwm_signal'].rolling(50).mean()\n",
    "\n",
    "\n",
    "# shift signal and calculate returns\n",
    "df_all['cwm_signal'] = df_all['cwm_signal_slow'].shift(1)\n",
    "df_all['cwm_pnl'] = df_all['cwm_signal'] * df_all['mid_change']\n",
    "df_all['cwm_pnl'].cumsum().resample(\"1T\").last().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VWM - level 1 \n",
    "df_all['vwm'] = (df_all[\"Bid1Qty\"] * df_all[\"Offer1\"] + df_all[\"Bid1\"] * df_all[\"Offer1Qty\"])  / (df_all[\"Bid1Qty\"] + df_all[\"Offer1Qty\"])\n",
    "df_all['vwm_signal'] = np.where(df_all['vwm'] >= df_all['mid'], 1, -1)\n",
    "\n",
    "df_all['vwm_signal'] = np.where(df_all['vwm'] > df_all['mid'], 1, -1)\n",
    "\n",
    "# shift the signal\n",
    "df_all['vwm_signal'] = df_all['vwm_signal'].shift(1)\n",
    "\n",
    "# calculate returns\n",
    "df_all['vwm_pnl'] = df_all['vwm_signal'] * df_all['mid_change']\n",
    "df_all['vwm_pnl'].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Trend and Crossover\n",
    "####################\n",
    "\n",
    "trend_lookback = 500\n",
    "\n",
    "crossover_1_lookback = 100\n",
    "crossover_2_lookback = 500\n",
    "\n",
    "# simple trend following model for mid generation\n",
    "df_all['trend_signal'] = np.where(df_all['mid'] > df_all['mid'].rolling(trend_lookback).mean(), 1, -1)\n",
    "df_all['trend_signal'] = df_all['trend_signal'].shift(1)\n",
    "df_all['trend_pnl'] = df_all['trend_signal'] * df_all['mid_change']\n",
    "\n",
    "# ma crossover\n",
    "df_all['crossover_signal'] = np.where(df_all['mid'].rolling(crossover_1_lookback).mean() > df_all['mid'].rolling(crossover_2_lookback).mean(), 1, -1)\n",
    "df_all['crossover_signal'] = df_all['crossover_signal'].shift(1)\n",
    "df_all['crossover_pnl'] = df_all['crossover_signal'] * df_all['mid_change']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['crossover_pnl', 'trend_pnl']].between_time('00:00', '22:00').cumsum().resample(\"1T\").last().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['combined_signal'] = np.sign(df_all['ofi_signal'] + df_all['trend_signal'] + df_all['cwm_signal'])\n",
    "df_all['combined_pnl'] = df_all['mid_change'] * df_all['combined_signal']\n",
    "df_all['combined_pnl'].between_time('07:00', '19:00').cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 10ms breakout signal and combine with OFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout_signal = hloc_filtered['overall_position'].resample(ofi_resample).last().ffill()\n",
    "breakout_signal = np.sign(breakout_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout_signal.resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"breakout_signal\"] = breakout_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"breakout_pnl\"] = df_all[\"breakout_signal\"] * df_all['mid_change']\n",
    "\n",
    "df_all[\"breakout_pnl\"].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt signal - Regime Switching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adapt_rolling = 10000\n",
    "\n",
    "df_all['ofi_pnl_ma'] = df_all['ofi_pnl'].rolling(adapt_rolling).mean()\n",
    "df_all['trend_pnl_ma'] = df_all['trend_pnl'].rolling(adapt_rolling).mean()\n",
    "df_all['cwm_pnl_ma'] = df_all['cwm_pnl'].rolling(adapt_rolling).mean()\n",
    "df_all['breakout_pnl_ma'] = df_all['breakout_pnl'].rolling(adapt_rolling).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['combined_pnl_ma'] = (df_all['ofi_pnl_ma'] + df_all['trend_pnl_ma'] + df_all['breakout_pnl_ma']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_weight'] = np.where(df_all['ofi_pnl_ma'] > 0, 1, 0)\n",
    "df_all['ofi_weight'] = df_all['ofi_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['trend_weight'] = np.where(df_all['trend_pnl_ma'] > 0, 1, 0)\n",
    "df_all['trend_weight'] = df_all['trend_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['cwm_weight'] = np.where(df_all['cwm_pnl_ma'] > 0, 1, 0)\n",
    "df_all['cwm_weight'] = df_all['cwm_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['breakout_weight'] = np.where(df_all['breakout_pnl_ma'] > 0, 1, 0)\n",
    "df_all['breakout_weight'] = df_all['breakout_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two versions of the adapt\n",
    "\n",
    "# weighted by recent pnl\n",
    "df_all['adapt_signal'] = np.sign(\n",
    "    (df_all['breakout_weight'] * df_all['breakout_signal']) + \n",
    "    (df_all['trend_weight'] * df_all['trend_signal']) +\n",
    "    (df_all['ofi_weight'] * df_all['ofi_signal'])\n",
    ")\n",
    "\n",
    "# unweighted \n",
    "# df_all['adapt_signal'] = np.sign(\n",
    "#     df_all['breakout_signal'] +\n",
    "#     df_all['trend_signal'] +\n",
    "#     df_all['ofi_signal']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_pnl'] = df_all['mid_change'] * df_all['adapt_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_pnl'].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pnl Per Trade and Holding Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Counts the number of ticks between changes in the signal\n",
    "# Calculates pnl per trade \n",
    "###############\n",
    "\n",
    "# these are the df and column for the signals \n",
    "signal_df = df_all\n",
    "signal_column = 'adapt_signal'\n",
    "\n",
    "# the df and column for the pnl\n",
    "pnl_column = df_all['adapt_pnl']\n",
    "\n",
    "\n",
    "def SignalPersisenceFast(df,column_name): \n",
    "    array= df[column_name].values\n",
    "    previous_signal  = False \n",
    "    Counter = 0\n",
    "    Times = []\n",
    "    for x in range(len(array)):\n",
    "        if((array[x] == previous_signal or Counter == 0) and array[x] != 0):\n",
    "            Counter = Counter + 1\n",
    "        else:\n",
    "            Times.append(Counter)\n",
    "            if array[x] != 0 : \n",
    "                Counter =  1\n",
    "        previous_signal = array[x]\n",
    "    return Times\n",
    "\n",
    "Times = SignalPersisenceFast(df_all,signal_column)\n",
    "number_trades = (df_all[\"s\"].count() / np.mean(Times))\n",
    "pnl_per_trade = pnl_column.sum() / number_trades\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**configs**\")\n",
    "print(\"adapt rolling: \"f'{adapt_rolling:d}')\n",
    "print(\"trend lookback: \"f'{trend_lookback:.0f}')\n",
    "print(\"ofi rolling: \"f'{ofi_lookback:.0f}')\n",
    "print(\"ofi resample ms: \"f'{ofi_resample}')\n",
    "print()\n",
    "\n",
    "print(\"**time in signal/trade**\")\n",
    "print(\"Mean units of time in trade \"f'{(np.mean(Times)):.2f}')\n",
    "print(\"25 percentile time in trade \" + str(np.percentile(Times, 25, axis=0)))\n",
    "print(\"Median time in trade \" + str(np.median(Times)))\n",
    "print(\"75 percentile time in trade \" + str(np.percentile(Times, 75, axis=0)))\n",
    "print()\n",
    "\n",
    "print(\"**performance stats**\")\n",
    "print(\"Number of signals/trades: \"f'{number_trades:.0f}')\n",
    "print(\"Cumulative PnL %: \"f'{(pnl_column.sum() * 100):.2f}')\n",
    "print(\"Average Trade PnL $ per million \"f'{(pnl_per_trade*1000000):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A book strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotes = df_all.copy()\n",
    "df_quotes = df_quotes.loc[date_filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%add a suffix\n",
    "df_quotes = df_quotes.add_suffix('_quotes')\n",
    "\n",
    "# %% Read the data\n",
    "# Load trades\n",
    "df_trades = pd.read_csv(filename_futures_trades)\n",
    "\n",
    "# Function that adds the rolling long ash short position to the dataframe and average fill\n",
    "df_trades['buys_factor'] = 0  # delete after use\n",
    "df_trades['sells_factor'] = 0  # delete after use\n",
    "\n",
    "df_trades.loc[df_trades['side'] == 'sell', 'sells_factor'] = df_trades['fillPrice'] * df_trades['filledQuantity']\n",
    "df_trades.loc[df_trades['side'] == 'buy', 'buys_factor'] = df_trades['fillPrice'] * df_trades['filledQuantity']\n",
    "df_trades.loc[df_trades['side'] == 'sell', 'cum_sell'] = df_trades.loc[\n",
    "    df_trades['side'] == 'sell', 'filledQuantity'].cumsum()\n",
    "df_trades.loc[df_trades['side'] == 'buy', 'cum_buys'] = df_trades.loc[\n",
    "    df_trades['side'] == 'buy', 'filledQuantity'].cumsum()\n",
    "df_trades.loc[df_trades['side'] == 'sell', 'average_sell_price'] = df_trades['sells_factor'].cumsum() / df_trades[\n",
    "    'cum_sell']\n",
    "df_trades.loc[df_trades['side'] == 'buy', 'average_buy_price'] = df_trades['buys_factor'].cumsum() / df_trades[\n",
    "    'cum_buys']\n",
    "\n",
    "# Set the index\n",
    "df_trades[\"timestamp\"] = df_trades[\"transactTime\"]\n",
    "df_trades[\"timestamp\"] = pd.to_datetime(df_trades[\"timestamp\"])\n",
    "\n",
    "df_trades.set_index(\"timestamp\", inplace=True)\n",
    "df_trades.sort_index(inplace=True)\n",
    "\n",
    "# drop unused columns\n",
    "# df_trades.to_parquet(filename_trades + \".parq\", compression=\"snappy\")\n",
    "\n",
    "# df_trades = df_trades[['fillPrice','filledQuantity','side','cum_sell','average_sell_price','cum_buys','average_buy_price']]\n",
    "df_trades = df_trades.loc[date_filter]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Calcuate the weighted averages for the trades\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def weighted_average(group):\n",
    "    weights = group['filledQuantity']\n",
    "    height = group['fillPrice']\n",
    "    return np.average(height, weights=weights)\n",
    "\n",
    "\n",
    "grouped = df_trades.groupby(['timestamp', 'side']).apply(weighted_average).unstack()\n",
    "grouped = grouped.add_suffix('_price')\n",
    "grouped2 = df_trades.groupby(['timestamp', 'side'])['filledQuantity'].apply(sum).unstack()\n",
    "grouped2 = grouped2.add_suffix('_qty')\n",
    "grouped = pd.concat([grouped, grouped2], axis=1, sort=True)\n",
    "grouped = grouped[['buy_price', 'sell_price', 'buy_qty', 'sell_qty']]\n",
    "grouped.columns = ['OFFER_price', 'BID_price', 'OFFER_qty', 'BID_qty']\n",
    "grouped.index = pd.to_datetime(grouped.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Join the CFDs with the future quotes\n",
    "result_final = pd.concat([grouped, df_quotes], axis=1, sort=True)\n",
    "result_final = result_final[\n",
    "    ['BID_price', 'OFFER_price', 'BID_qty', 'OFFER_qty', 'adapt_signal_quotes', 'Bid0_quotes', 'Offer0_quotes',\n",
    "     'mid_quotes']]\n",
    "result_final.sort_index(inplace=True)\n",
    "\n",
    "cols = ['Bid0_quotes', 'Offer0_quotes', 'adapt_signal_quotes']\n",
    "result_final.loc[:, cols] = result_final.loc[:, cols].fillna(method=\"ffill\")\n",
    "\n",
    "# Calculate the mid\n",
    "result_final['mid_quotes'] = (result_final['Bid0_quotes'] + result_final['Offer0_quotes']) / 2\n",
    "\n",
    "cols = ['BID_qty', 'OFFER_qty']\n",
    "result_final.loc[:, cols] = result_final.loc[:, cols].fillna(0)\n",
    "\n",
    "# Trim the dataframe to the point of the first trade\n",
    "result_final = result_final.loc[result_final.index >= grouped.index[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "result_final['delayed_bid'] = np.nan\n",
    "result_final['delayed_offer'] = np.nan\n",
    "result_final['delayed_mid'] = result_final['mid_quotes']\n",
    "\n",
    "delayed_mid_index = result_final.columns.get_loc('delayed_mid')\n",
    "delayed_bid_index = result_final.columns.get_loc('delayed_bid')\n",
    "delayed_offer_index = result_final.columns.get_loc('delayed_offer')\n",
    "BID_price_index = result_final.columns.get_loc('BID_price')\n",
    "OFFER_price_index = result_final.columns.get_loc('OFFER_price')\n",
    "ofi_signal_quotes_index = result_final.columns.get_loc('adapt_signal_quotes')\n",
    "Bid0_CFD_index = result_final.columns.get_loc('Bid0_quotes')\n",
    "Offer0_CFD_index = result_final.columns.get_loc('Offer0_quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'BID_price','OFFER_price','BID_qty','OFFER_qty','Bid0_CFD', 'Offer0_CFD','ofi_signal_quotes'\n",
    "result_final_columns = result_final.columns\n",
    "array = result_final.values\n",
    "for i in range(array.shape[0]):\n",
    "    # We want to sell but the signal says up\n",
    "    if (array[i, BID_price_index] > 0) & (array[i, ofi_signal_quotes_index] > 0):\n",
    "        # Delay the execution\n",
    "        for i_inner in range(i, array.shape[0]):\n",
    "            if array[i_inner, ofi_signal_quotes_index] < 0:\n",
    "                array[i, delayed_bid_index] = array[i_inner, Bid0_CFD_index]\n",
    "                array[i, delayed_mid_index] = (array[i_inner, Bid0_CFD_index] + array[i_inner, Offer0_CFD_index]) / 2\n",
    "                break\n",
    "    if (array[i, OFFER_price_index] > 0) & (array[i, ofi_signal_quotes_index] < 0):\n",
    "        # Delay the execution\n",
    "        for i_inner in range(i, array.shape[0]):\n",
    "            if array[i_inner, ofi_signal_quotes_index] > 0:\n",
    "                array[i, delayed_offer_index] = array[i_inner, Offer0_CFD_index]\n",
    "                array[i, delayed_mid_index] = (array[i_inner, Bid0_CFD_index] + array[i_inner, Offer0_CFD_index]) / 2\n",
    "                break\n",
    "\n",
    "result_final = pd.DataFrame(data=array, index=result_final.index, columns=result_final_columns)\n",
    "\n",
    "del array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Look at the savings\n",
    "\n",
    "mean = df_trades['filledQuantity'].mean()\n",
    "result_final['saving'] = 0\n",
    "result_final.loc[result_final['BID_qty'] > 0, 'saving'] = result_final['delayed_mid'] - result_final['mid_quotes']\n",
    "result_final.loc[result_final['OFFER_qty'] > 0, 'saving'] = result_final['mid_quotes'] - result_final['delayed_mid']\n",
    "# result_final['saving'].cumsum().plot()\n",
    "\n",
    "result_final['saving_pct'] = 0\n",
    "result_final.loc[result_final['BID_qty'] > 0, 'saving_pct'] = (result_final['delayed_mid'] - result_final[\n",
    "    'mid_quotes']) / result_final['mid_quotes']\n",
    "result_final.loc[result_final['OFFER_qty'] > 0, 'saving_pct'] = (result_final['mid_quotes'] - result_final[\n",
    "    'delayed_mid']) / result_final['delayed_mid']\n",
    "# result_final['saving_pct'].cumsum().plot()\n",
    "\n",
    "(result_final['saving_pct'] * mean).cumsum().plot()\n",
    "saving_dollars = result_final['saving_pct'] * df_trades['filledQuantity']\n",
    "# result_final.loc[(result_final['OFFER_qty'] > 0) | (result_final['BID_qty'] > 0),'saving']\n",
    "# result_final.loc[result_final['saving']>0,'saving'].count() / result_final.loc[result_final['saving']<0,'saving'].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vol = df_trades['filledQuantity'].sum()\n",
    "total_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_pm = 1000000*(result_final['saving_pct'] * mean).sum()/(result_final.loc[(result_final['BID_qty']) > 0 | (result_final['OFFER_qty']>0),'saving'].count() * mean)\n",
    "yield_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
