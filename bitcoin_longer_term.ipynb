{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "# charting libraries\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Definitions\n",
    "#################\n",
    "# jeff/AUDUSD_20200212-060000_20200212-180000/2020-02-12T06:00:00.013Z-2020-02-12T18:00:00.866Z-Input_FASTMATCH-EBSDIRECT-REUTERS-HOTSPOT-GTX-CNX-FXALL_top1-1.csv.gz\n",
    "# Where to read data from\n",
    "s3_bucket    = 'mfx-sagemaker-dev'\n",
    "\n",
    "s3_signal_data_key = \"demo/XBTUSD_20200809-000000_20200821-120000/2020-08-09T21:01:08.578Z-2020-08-21T12:00:00.982Z-Input_DVCHAIN_top1-1.csv.gz\"\n",
    "\n",
    "s3_signal_data_key = \"demo/XBTUSD_20200821-000000_20200910-000000/2020-08-21T00:00:00.609Z-2020-09-10T00:00:00.874Z-Input_DVCHAIN_top1-1.csv.gz\"\n",
    "\n",
    "# Bar size\n",
    "resample_period = '60t'\n",
    "\n",
    "# Chart settings\n",
    "chart_padding_secs = 10\n",
    "\n",
    "# Breakout settings\n",
    "breakout_sigma = 2.0\n",
    "\n",
    "# MR settings\n",
    "mr_sigma = 3\n",
    "\n",
    "# Hedging level\n",
    "hedge_level = 5\n",
    "\n",
    "# Hedger interest to fill time in ms\n",
    "interest_to_fill = 10\n",
    "\n",
    "\n",
    "\n",
    "# n samples for moving average\n",
    "ma_samples = \"120t\"\n",
    "\n",
    "# optimise exits\n",
    "optimise_exit = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Load from S3\n",
    "#################\n",
    "\n",
    "signal_tick_data = pd.read_csv('s3://{}/{}'.format(s3_bucket, s3_signal_data_key), index_col='t', parse_dates=['t'])\n",
    "trigger_tick_data = signal_tick_data\n",
    "\n",
    "reval_tick_data = signal_tick_data\n",
    "# Source for tick charts\n",
    "chart_tick_data = reval_tick_data\n",
    "\n",
    "signal_tick_data['spread'] = signal_tick_data['Offer0'] - signal_tick_data['Bid0']\n",
    "reval_tick_data['spread'] = reval_tick_data['Offer0'] - reval_tick_data['Bid0']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Aggregate tick data\n",
    "#################\n",
    "signal_mid_price_series = (signal_tick_data.loc[:, 'Bid0'] + signal_tick_data.loc[:, 'Offer0']) / 2\n",
    "trigger_mid_price_series = (trigger_tick_data.loc[:, 'Bid0'] + trigger_tick_data.loc[:, 'Offer0']) / 2\n",
    "reval_mid_price_series = (reval_tick_data.loc[:, 'Bid0'] + reval_tick_data.loc[:, 'Offer0']) / 2\n",
    "# print(reval_mid_price_series.tail())\n",
    "\n",
    "# reval_mid_price_series['reference_mid'] = signal_mid_price_series.asof(reval_mid_price_series.index)\n",
    "# print(signal_mid_price_series.asof(reval_mid_price_series.index), reval_mid_price_series)\n",
    "bar_sampler = signal_mid_price_series.resample(resample_period)\n",
    "\n",
    "hloc = bar_sampler.ohlc() # **FIXME** First tick in bar not last tick in previous bar?\n",
    "\n",
    "# display(hloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Derived columns\n",
    "#################\n",
    "\n",
    "hloc['o_to_h'] = (hloc['high'] / hloc['open'] - 1)\n",
    "hloc['o_to_l'] = (hloc['low'] / hloc['open'] - 1)\n",
    "hloc['c_to_c'] = hloc['close'].pct_change()\n",
    "\n",
    "hloc['o_to_h_vol'] = hloc['o_to_h'].rolling(ma_samples).std()\n",
    "hloc['o_to_l_vol'] = hloc['o_to_l'].rolling(ma_samples).std()\n",
    "hloc['c_to_c_vol'] = hloc['c_to_c'].rolling(ma_samples).std()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# hloc['6_hr_ma'] = hloc['close'].rolling(6).mean()\n",
    "# hloc['6_hr_ma_sig'] = np.where(hloc['close'].shift(1) > hloc['6_hr_ma'].shift(1), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Trigger check\n",
    "#################\n",
    "\n",
    "def mid_trigger_price (timestamp, where): \n",
    "    index = trigger_mid_price_series[timestamp : timestamp + timestamp.freq].where(where).dropna().first_valid_index()\n",
    "    if index == None :\n",
    "        return None\n",
    "    result = reval_mid_price_series.asof(index)\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def trigger_check(row, high_trigger_col, low_trigger_col, high_side):\n",
    "    \n",
    "    triggers = [\n",
    "        ['High', mid_trigger_price(row.name, lambda price: price.gt(row[high_trigger_col])), \n",
    "                 +high_side, row[high_trigger_col]],\n",
    "        ['Low', mid_trigger_price(row.name, lambda price: price.lt(row[low_trigger_col])),\n",
    "                -high_side, row[low_trigger_col]]\n",
    "    ]\n",
    "    \n",
    "    triggers = [t for t in triggers if t[1] is not None]\n",
    "    \n",
    "    triggers.sort(key=lambda t : t[1])\n",
    "    \n",
    "    if not triggers:\n",
    "        return None\n",
    "    \n",
    "    return triggers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Breakout signals\n",
    "#################\n",
    "\n",
    "hloc['breakout_high_trigger'] = hloc['open'] * (1 + (breakout_sigma * (hloc['o_to_h_vol'].shift(1))))\n",
    "hloc['breakout_low_trigger'] = hloc['open'] * (1 - (breakout_sigma * (hloc['o_to_l_vol'].shift(1))))\n",
    "\n",
    "hloc['breakout_triggered'] = hloc.apply(lambda row: trigger_check(row, 'breakout_high_trigger', 'breakout_low_trigger', 1), axis=1)\n",
    "hloc['breakout_triggered'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Mean reversion signals\n",
    "#################\n",
    "\n",
    "hloc['6_hr_ma'] = hloc['close'].rolling(ma_samples).mean()\n",
    "# hloc['6_hr_ma_sig'] = np.where(hloc['close'].shift(1) > hloc['6_hr_ma'].shift(1), 1, -1)\n",
    "\n",
    "hloc['mr_high_trigger'] = hloc['6_hr_ma'] * (1 + (mr_sigma * (hloc['c_to_c_vol'].shift(1))))\n",
    "hloc['mr_low_trigger'] = hloc['6_hr_ma'] * (1 - (mr_sigma * (hloc['c_to_c_vol'].shift(1))))\n",
    "\n",
    "hloc['mr_triggered'] = hloc.apply(lambda row: trigger_check(row, 'mr_high_trigger', 'mr_low_trigger', -1), axis=1)\n",
    "hloc.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered = hloc\n",
    "# .between_time('00:30', '20:00')\n",
    "# hloc.to_csv('test_4.csv')\n",
    "# hloc_filtered.to_csv('test_5.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# position\n",
    "\n",
    "hloc_filtered['breakout_trade'] = hloc_filtered['breakout_triggered'].map(lambda x: 0 if x is None else x[2])\n",
    "hloc_filtered['breakout_trade_price'] = hloc_filtered['breakout_triggered'].map(lambda x: 0 if x is None else x[1])\n",
    "hloc_filtered['breakout_contra_trade_amount'] = -1 * hloc_filtered['breakout_trade'] * hloc_filtered['breakout_trade_price']\n",
    "\n",
    "hloc_filtered['mr_trade'] = hloc_filtered['mr_triggered'].map(lambda x: 0 if x is None else x[2])\n",
    "hloc_filtered['mr_trade_price'] = hloc_filtered['mr_triggered'].map(lambda x: 0 if x is None else x[1])\n",
    "hloc_filtered['mr_contra_trade_amount'] = -1 * hloc_filtered['mr_trade'] * hloc_filtered['mr_trade_price']\n",
    "hloc_filtered['position'] = hloc_filtered['breakout_trade'].cumsum() + hloc_filtered['mr_trade'].cumsum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdev = np.std(hloc_filtered['close'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hedge trades\n",
    "hloc_filtered['hedge_trade'] = 0.0\n",
    "hloc_filtered['hedge_price'] = 0.0\n",
    "hedge_trade_sum = 0.0\n",
    "hloc_filtered['hedge_contra_amount'] = 0.0\n",
    "current_position = 0.0\n",
    "keep_position = False\n",
    "i_prev = None\n",
    "n = len(hloc_filtered)\n",
    " \n",
    "for i in hloc_filtered.index:\n",
    "    stay_long, stay_short = False, False\n",
    "    current_position = hloc_filtered.loc[i]['position'] + hedge_trade_sum\n",
    "    \n",
    "    if(optimise_exit) :\n",
    "        if current_position > 0 and (hloc_filtered.loc[i]['close'] > (hloc_filtered.loc[i_prev]['close'] + 2.5 * stdev)):\n",
    "            stay_long = True\n",
    "        if current_position < 0 and (hloc_filtered.loc[i]['close'] < (hloc_filtered.loc[i_prev]['close'] - 2.5 * stdev)):\n",
    "            stay_short = True\n",
    "        keep_position = stay_long or stay_short\n",
    "    \n",
    "    if i_prev and not keep_position and (np.absolute(current_position) >= hedge_level):\n",
    "        hloc_filtered.loc[i,'hedge_trade'] = -1 * current_position\n",
    "        hedge_trade_sum += -1 * current_position\n",
    "        # TODO: Review\n",
    "        hedge_price = hloc_filtered.asof(i + pd.Timedelta(milliseconds=interest_to_fill),\n",
    "                                         subset=['close'])['close']\n",
    "        hloc_filtered.loc[i,'hedge_price'] = hedge_price\n",
    "        hloc_filtered.loc[i,'hedge_contra_amount'] = -1 * hloc_filtered.loc[i,'hedge_trade'] * \\\n",
    "                                                     hloc_filtered.loc[i,'hedge_price']\n",
    "    i_prev = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['hedge_balance'] = hloc_filtered['hedge_trade'].cumsum()\n",
    "hloc_filtered['overall_position'] = hloc_filtered['breakout_trade'].cumsum() + hloc_filtered['mr_trade'].cumsum() + hloc_filtered['hedge_trade'].cumsum()\n",
    "hloc_filtered['overall_contra_position'] = hloc_filtered['breakout_contra_trade_amount'].cumsum() + hloc_filtered['mr_contra_trade_amount'].cumsum() + hloc_filtered['hedge_contra_amount'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pnl\n",
    "hloc_filtered['pnl'] = np.where(hloc_filtered['overall_position'] == 0, hloc_filtered['overall_contra_position'], hloc_filtered['overall_position'] * hloc_filtered['close'] + hloc_filtered['overall_contra_position'])\n",
    "hloc_filtered['pnl_pct'] = hloc_filtered[\"pnl\"] / hloc_filtered[\"close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot mr strategy returns\n",
    "hloc_filtered['pnl'].resample(\"60T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['c_to_c_vol'].resample(\"60T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(hloc_filtered['overall_position']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volumes, pnl and yield\n",
    "y = 0\n",
    "breakout_volume = np.abs(hloc_filtered['breakout_trade']).sum()\n",
    "mr_volume = np.abs(hloc_filtered['mr_trade']).sum()\n",
    "hedge_volume = np.abs(hloc_filtered['hedge_trade']).sum()\n",
    "total_volume = breakout_volume + mr_volume + hedge_volume\n",
    "total_pnl = hloc_filtered['pnl'].tail(1)\n",
    "y = total_pnl / total_volume \n",
    "display(breakout_volume, mr_volume, hedge_volume, total_volume, total_pnl, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered.tail(20).to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Flow Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ofi(quotes,level):\n",
    "    \"\"\"Returns Order Flow Imbalance for given levels of the orderbook\"\"\"\n",
    "    qdf = quotes.copy()\n",
    "    bid_price_label = 'Bid' + str(level)\n",
    "    offer_price_label = 'Offer' + str(level)\n",
    "    bid_qty_label = 'Bid' +str(level) + 'Qty'\n",
    "    offer_qty_label = 'Offer' + str(level)+'Qty'\n",
    "\n",
    "    qdf['prev_bidprice'] = qdf[bid_price_label].shift()\n",
    "    qdf['prev_bidsize'] = qdf[bid_qty_label].shift()\n",
    "    qdf['prev_askprice'] = qdf[offer_price_label].shift()\n",
    "    qdf['prev_asksize'] = qdf[offer_qty_label].shift()\n",
    "\n",
    "    # Fix any missing/invalid data\n",
    "    qdf.replace([np.inf, np.NINF], np.nan, inplace=True)\n",
    "    qdf.fillna(method=\"ffill\", inplace=True)\n",
    "    qdf.fillna(method=\"bfill\", inplace=True)\n",
    "    \n",
    "    bid_geq = qdf[bid_price_label] >= qdf['prev_bidprice']\n",
    "    bid_leq = qdf[bid_price_label] <= qdf['prev_bidprice']\n",
    "    ask_geq = qdf[offer_price_label] >= qdf['prev_askprice']\n",
    "    ask_leq = qdf[offer_price_label] <= qdf['prev_askprice']\n",
    "    \n",
    "    qdf['ofi'] = np.zeros(len(qdf))\n",
    "    qdf['ofi'].loc[bid_geq] += qdf[bid_qty_label].loc[bid_geq]\n",
    "    qdf['ofi'].loc[bid_leq] -= qdf['prev_bidsize'].loc[bid_leq]\n",
    "    qdf['ofi'].loc[ask_geq] += qdf['prev_asksize'].loc[ask_geq]\n",
    "    qdf['ofi'].loc[ask_leq] -= qdf[offer_qty_label].loc[ask_leq]    \n",
    "    return qdf['ofi']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# OFI using top x levels \n",
    "########################\n",
    "\n",
    "# df_all = pd.read_csv('s3://{}/{}'.format(s3_bucket, s3_signal_data_key), index_col='t', parse_dates=['t'])\n",
    "\n",
    "# df_all = df_all.resample(\"100ms\").last().ffill()\n",
    "\n",
    "df_all = signal_tick_data.resample(\"100ms\").last().ffill()\n",
    "df_all = df_all\n",
    "\n",
    "df_all[\"Offer0Qty\"] = df_all[\"Offer0Qty\"].astype('float')\n",
    "df_all[\"Offer0\"] = df_all[\"Offer0\"].astype('float')\n",
    "df_all[\"Bid0\"] = df_all[\"Bid0\"].astype('float')\n",
    "df_all[\"Bid0Qty\"] = df_all[\"Bid0Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer1Qty\"] = df_all[\"Offer1Qty\"].astype('float')\n",
    "df_all[\"Offer1\"] = df_all[\"Offer1\"].astype('float')\n",
    "df_all[\"Bid1\"] = df_all[\"Bid1\"].astype('float')\n",
    "df_all[\"Bid1Qty\"] = df_all[\"Bid1Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer2Qty\"] = df_all[\"Offer2Qty\"].astype('float')\n",
    "df_all[\"Offer2\"] = df_all[\"Offer2\"].astype('float')\n",
    "df_all[\"Bid2\"] = df_all[\"Bid2\"].astype('float')\n",
    "df_all[\"Bid2Qty\"] = df_all[\"Bid2Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer3Qty\"] = df_all[\"Offer3Qty\"].astype('float')\n",
    "df_all[\"Offer3\"] = df_all[\"Offer3\"].astype('float')\n",
    "df_all[\"Bid3\"] = df_all[\"Bid3\"].astype('float')\n",
    "df_all[\"Bid3Qty\"] = df_all[\"Bid3Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer4Qty\"] = df_all[\"Offer4Qty\"].astype('float')\n",
    "df_all[\"Offer4\"] = df_all[\"Offer4\"].astype('float')\n",
    "df_all[\"Bid4\"] = df_all[\"Bid4\"].astype('float')\n",
    "df_all[\"Bid4Qty\"] = df_all[\"Bid4Qty\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFI with levels 1, 2 and 3 (works better than 0,1,2)\n",
    "# 100 period MA works well\n",
    "\n",
    "df_all['ofi'] = ofi(df_all,1) +ofi(df_all,2) +ofi(df_all,3) \n",
    "df_all['ofi_signal'] = np.where(df_all['ofi'].rolling(200).mean() > 0, 1, -1)\n",
    "df_all['mid'] = ((df_all['Bid0'] + df_all['Offer0']) / 2.0)\n",
    "df_all['mid_change'] = ((df_all['Bid0'] + df_all['Offer0']) / 2.0).pct_change()\n",
    "\n",
    "\n",
    "# shift the signal\n",
    "df_all['ofi_signal'] = df_all['ofi_signal'].shift(1)\n",
    "df_all['ofi_pnl'] = (df_all['ofi_signal'] * df_all['mid_change'])\n",
    "\n",
    "print(\"Cumulative PnL \" + str(df_all['ofi_pnl'].cumsum().iloc[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_pnl'].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_signal'].rolling(\"90t\").sum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*90*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofi_direction = np.sign(df_all['ofi_signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofi_direction.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Weighted Mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Volume Weighted Mids\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CWM\n",
    "df_all['weighted_bid_notional_5'] =  df_all[\"Bid1Qty\"] + df_all[\"Bid2Qty\"] + df_all[\"Bid3Qty\"] + df_all[\"Bid4Qty\"]\n",
    "df_all['weighted_offer_notional_5'] =  df_all[\"Offer1Qty\"] + df_all[\"Offer2Qty\"] + df_all[\"Offer3Qty\"] + df_all[\"Offer4Qty\"]\n",
    "df_all['weighted_bid_5'] = (df_all[\"Bid1Qty\"] * df_all[\"Bid1\"] + df_all[\"Bid2Qty\"] * df_all[\"Bid2\"] + df_all[\"Bid3Qty\"] * df_all[\"Bid3\"] + df_all[\"Bid4Qty\"] * df_all[\"Bid4\"]) / df_all['weighted_bid_notional_5'] \n",
    "df_all['weighted_offer_5'] = ( df_all[\"Offer1Qty\"] * df_all[\"Offer1\"] + df_all[\"Offer2Qty\"] * df_all[\"Offer2\"] + df_all[\"Offer3Qty\"] * df_all[\"Offer3\"] + df_all[\"Offer4Qty\"] * df_all[\"Offer4\"]) / df_all['weighted_offer_notional_5'] \n",
    "df_all['conventionally_weighted_mid_5'] = (df_all['weighted_bid_5'] + df_all['weighted_offer_5']) / 2\n",
    "df_all['cwm'] = df_all['conventionally_weighted_mid_5']\n",
    "df_all['cwm_signal'] = np.where(df_all['cwm'] >= df_all['mid'], 1, -1)\n",
    "\n",
    "\n",
    "# slow down to XTX pace \n",
    "df_all['cwm_signal_slow'] = df_all['cwm_signal'].rolling(10).mean()\n",
    "\n",
    "\n",
    "# shift signal and calculate returns\n",
    "df_all['cwm_signal'] = df_all['cwm_signal_slow'].shift(1)\n",
    "df_all['cwm_pnl'] = df_all['cwm_signal'] * df_all['mid_change']\n",
    "df_all['cwm_pnl'].cumsum().resample(\"1T\").last().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VWM - level 0 inverse\n",
    "df_all['inverse_vwm'] = (df_all[\"Bid0Qty\"] * df_all[\"Offer0\"] + df_all[\"Bid0\"] * df_all[\"Offer0Qty\"])  / (df_all[\"Bid0Qty\"] + df_all[\"Offer0Qty\"])\n",
    "df_all['inverse_signal'] = np.where(df_all['inverse_vwm'] >= df_all['mid'], -1, 1)\n",
    "\n",
    "# shift signal\n",
    "df_all['inverse_signal'].shift(1)\n",
    "\n",
    "# calculate returns\n",
    "df_all['inverse_pnl'] = df_all['inverse_signal'] * df_all['mid_change']\n",
    "df_all['inverse_pnl'].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VWM - level 1 \n",
    "df_all['vwm'] = (df_all[\"Bid1Qty\"] * df_all[\"Offer1\"] + df_all[\"Bid1\"] * df_all[\"Offer1Qty\"])  / (df_all[\"Bid1Qty\"] + df_all[\"Offer1Qty\"])\n",
    "df_all['vwm_signal'] = np.where(df_all['vwm'] >= df_all['mid'], 1, -1)\n",
    "\n",
    "df_all['vwm_signal'] = np.where(df_all['vwm'] > df_all['mid'], 1, -1)\n",
    "\n",
    "# shift the signal\n",
    "df_all['vwm_signal'] = df_all['vwm_signal'].shift(1)\n",
    "\n",
    "# calculate returns\n",
    "df_all['vwm_pnl'] = df_all['vwm_signal'] * df_all['mid_change']\n",
    "df_all['vwm_pnl'].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Trend and Crossover\n",
    "####################\n",
    "\n",
    "# simple trend following model for mid generation\n",
    "df_all['trend_signal'] = np.where(df_all['mid'] > df_all['mid'].rolling(75).mean(), 1, -1)\n",
    "df_all['trend_signal'] = df_all['trend_signal'].shift(1)\n",
    "df_all['trend_return'] = df_all['trend_signal'] * df_all['mid_change']\n",
    "\n",
    "# ma crossover\n",
    "df_all['crossover_signal'] = np.where(df_all['mid'].rolling(100).mean() > df_all['mid'].rolling(500).mean(), 1, -1)\n",
    "df_all['crossover_signal'] = df_all['crossover_signal'].shift(1)\n",
    "df_all['crossover_return'] = df_all['crossover_signal'] * df_all['mid_change']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['crossover_return', 'trend_return']].between_time('00:00', '22:00').cumsum().resample(\"1T\").last().plot()\n",
    "# df_all[['crossover_return', 'trend_return']].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['combined_signal'] = np.sign(df_all['ofi_signal'] + df_all['trend_signal'] + df_all['cwm_signal'])\n",
    "df_all['combined_pnl'] = df_all['mid_change'] * df_all['combined_signal']\n",
    "df_all['combined_pnl'].between_time('07:00', '19:00').cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt signal - Regime Switching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - slow the signals down so they have the same expected flip rate (5 seconds)\n",
    "#### Step 2 - calculate pnl moving average for each\n",
    "#### Step 3 - weight according to each distance to moving average\n",
    "#### make sure the shift is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_pnl_ma'] = df_all['ofi_pnl'].rolling(1000).mean()\n",
    "df_all['trend_pnl_ma'] = df_all['trend_return'].rolling(1000).mean()\n",
    "df_all['cwm_pnl_ma'] = df_all['cwm_pnl'].rolling(1000).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['combined_pnl_ma'] = (df_all['ofi_pnl_ma'] + df_all['trend_pnl_ma'] + df_all['cwm_pnl_ma']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_weight'] = df_all['ofi_pnl_ma'] / df_all['combined_pnl_ma']\n",
    "df_all['ofi_weight'] = np.max(df_all['ofi_weight'], 0)\n",
    "df_all['ofi_weight'] = df_all['ofi_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['trend_weight'] = df_all['trend_pnl_ma'] / df_all['combined_pnl_ma']\n",
    "df_all['trend_weight'] = np.max(df_all['trend_weight'], 0)\n",
    "df_all['trend_weight'] = df_all['trend_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['cwm_weight'] = df_all['cwm_pnl_ma'] / df_all['combined_pnl_ma']\n",
    "df_all['cwm_weight'] = np.max(df_all['cwm_weight'], 0)\n",
    "df_all['cwm_weight'] = df_all['cwm_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_signal'] = np.sign(\n",
    "    (df_all['cwm_weight'] * df_all['cwm_signal']) + \n",
    "    (df_all['trend_weight'] * df_all['trend_signal']) +\n",
    "    (df_all['ofi_weight'] * df_all['ofi_signal'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_pnl'] = df_all['mid_change'] * df_all['adapt_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_pnl'].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['60change'] = (df_all['mid'].shift(-3600) / df_all['mid'])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['60pnl'] = df_all['adapt_signal'] * df_all['60change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['60pnl'].cumsum().resample(\"1T\").last().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pnl Per Trade and Holding Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Counts the number of ticks between changes in the signal\n",
    "# Calculates pnl per trade \n",
    "###############\n",
    "\n",
    "# these are the df and column for the signals \n",
    "signal_df = df_all\n",
    "signal_column = 'adapt_signal'\n",
    "\n",
    "# the df and column for the pnl\n",
    "pnl_column = df_all['adapt_pnl']\n",
    "\n",
    "\n",
    "def SignalPersisenceFast(df,column_name): \n",
    "    array= df[column_name].values\n",
    "    previous_signal  = False \n",
    "    Counter = 0\n",
    "    Times = []\n",
    "    for x in range(len(array)):\n",
    "        if((array[x] == previous_signal or Counter == 0) and array[x] != 0):\n",
    "            Counter = Counter + 1\n",
    "        else:\n",
    "            Times.append(Counter)\n",
    "            if array[x] != 0 : \n",
    "                Counter =  1\n",
    "        previous_signal = array[x]\n",
    "    return Times\n",
    "\n",
    "Times = SignalPersisenceFast(df_all,signal_column)\n",
    "print(\"Mean time in trade \" + str(np.mean(Times)))\n",
    "print(\"Number of trades \" + str(len(Times)))\n",
    "print(\"Cumulative PnL \" + str(pnl_column.cumsum().iloc[-1]))\n",
    "print(\"Average Trade PnL \" + str(pnl_column.cumsum().iloc[-1] / len(Times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_signal_10'] = np.where(df_all['ofi'].rolling(10).mean() > 0, 1, -1)\n",
    "df_all['ofi_signal_25'] = np.where(df_all['ofi'].rolling(25).mean() > 0, 1, -1)\n",
    "df_all['ofi_signal_50'] = np.where(df_all['ofi'].rolling(50).mean() > 0, 1, -1)\n",
    "df_all['ofi_signal_100'] = np.where(df_all['ofi'].rolling(100).mean() > 0, 1, -1)\n",
    "df_all['ofi_signal_200'] = np.where(df_all['ofi'].rolling(200).mean() > 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['trend_sig_5'] = np.where(df_all['mid'] > df_all['mid'].rolling(5).mean(), 1, -1)\n",
    "df_all['trend_sig_10'] = np.where(df_all['mid'] > df_all['mid'].rolling(10).mean(), 1, -1)\n",
    "df_all['trend_sig_25'] = np.where(df_all['mid'] > df_all['mid'].rolling(25).mean(), 1, -1)\n",
    "df_all['trend_sig_50'] = np.where(df_all['mid'] > df_all['mid'].rolling(50).mean(), 1, -1)\n",
    "df_all['trend_sig_100'] = np.where(df_all['mid'] > df_all['mid'].rolling(100).mean(), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_filtered = df_all.between_time('09:00', '12:00')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Scatter(\n",
    "    x = df_all_filtered.index,\n",
    "    y = df_all_filtered['mid']\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_tickformat = '%H:%M:%S.%L'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis_tickformat = '.5f'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = df_all_filtered.index,\n",
    "    y = df_all_filtered['trend_sig_25'],\n",
    "    mode = 'lines',\n",
    "    name = '25'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = df_all_filtered.index,\n",
    "    y = df_all_filtered['trend_sig_50'],\n",
    "    mode = 'lines',\n",
    "    name = '50'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = df_all_filtered.index,\n",
    "    y = df_all_filtered['trend_sig_100'],\n",
    "    mode = 'lines',\n",
    "    name = '100'\n",
    ")\n",
    "\n",
    "\n",
    "data = [trace2]\n",
    "\n",
    "py.iplot(data, filename='line-mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
