{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research_utilities import *\n",
    "\n",
    "# import libraries\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "# set dataframe display options\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "# pd.set_option(\"display.precision\", 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Definitions\n",
    "#################\n",
    "# Where to read data from\n",
    "s3_bucket    = 'mfx-sagemaker-dev'\n",
    "\n",
    "s3_signal_data_key = \"demo/XAUUSD_20210101-000000_20210131-000000/2021-01-01T00:00:06.165Z-2021-01-29T21:59:59.113Z-Input_SAXO-MS-UBS-JUMP-LMAX-POP-JPM_RETAIL-INVAST-MS_ECN-JPM_INST-EDGEWATER-HOTSPOT-FXCM-XTX_top1-1.csv.gz\"\n",
    "\n",
    "\n",
    "# s3_signal_data_key = \"go-data/XBTUSD_20201115-210000_20201127-220000/2020-11-15T21:05:32.434Z-2020-11-27T21:59:00.452Z-Input_DVCHAIN-IG_top2-1.csv.gz\"\n",
    "\n",
    "# s3_signal_data_key = \"go-data/XAUUSD_20210103-220000_20210115-220000/2021-01-03T23:00:00.250Z-2021-01-15T21:59:58.123Z-Input_FASTMATCH-SAXO-CFH-INVAST-JPM-HOTSPOT-MORGAN_STANLEY-LMAX-JUMP-HC_TECH-XTX_top5-1.csv.gz\"\n",
    "\n",
    "# our_prices_key = \"go-data/GBPUSD_20201118-070000_20201118-130000/2020-11-18T07:00:00.055Z-2020-11-18T13:00:00.838Z-Output_CLIENT_INST_PRICE_LDN_top1-1.csv.gz\"\n",
    "\n",
    "# xtx_key = \"go-data/GBPUSD_20201118-070000_20201118-130000/2020-11-18T07:00:02.037Z-2020-11-18T13:00:00.575Z-Input_XTX_top5-1.csv.gz\"\n",
    "\n",
    "# %% data from Drive\n",
    "# google_drive_filename = \"/Volumes/GoogleDrive/Shared drives/data/think_xauusd_20200908_quotes.csv\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar size\n",
    "resample_period = '10s'\n",
    "\n",
    "# Chart settings\n",
    "chart_padding_secs = 10\n",
    "\n",
    "# Breakout settings\n",
    "breakout_sigma = 1.5\n",
    "\n",
    "# MR settings\n",
    "mr_sigma = 10\n",
    "\n",
    "# Hedging level\n",
    "hedge_level = 3\n",
    "\n",
    "# Hedger interest to fill time in ms\n",
    "interest_to_fill = 10000\n",
    "\n",
    "# n samples for moving average\n",
    "ma_samples = 3\n",
    "\n",
    "# optimise exits\n",
    "optimise_exit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################\n",
    "# Load from S3\n",
    "#################\n",
    "# using S3\n",
    "signal_tick_data = pd.read_csv('s3://{}/{}'.format(s3_bucket, s3_signal_data_key), index_col='t', parse_dates=['t'])\n",
    "# our_price = pd.read_csv('s3://{}/{}'.format(s3_bucket, our_prices_key), index_col='t', parse_dates=['t'])\n",
    "# xtx_prices = pd.read_csv('s3://{}/{}'.format(s3_bucket, xtx_key), index_col='t', parse_dates=['t'])\n",
    "\n",
    "# optionally from from Drive\n",
    "# google_drive_filename = \"/Volumes/GoogleDrive/Shared drives/data/echo/go_gbpusd_20200810_quotes.csv\"\n",
    "# signal_tick_data = pd.read_csv(google_drive_filename, index_col='t', parse_dates=['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resample if necessary\n",
    "# signal_tick_data = signal_tick_data[\"2021-01-08 14:00:00\":\"2021-01-08 15:00:00\"]\n",
    "\n",
    "\n",
    "trigger_tick_data = signal_tick_data\n",
    "reval_tick_data = signal_tick_data\n",
    "# Source for tick charts\n",
    "chart_tick_data = reval_tick_data\n",
    "\n",
    "signal_tick_data['spread'] = signal_tick_data['Offer0'] - signal_tick_data['Bid0']\n",
    "reval_tick_data['spread'] = reval_tick_data['Offer0'] - reval_tick_data['Bid0']\n",
    "\n",
    "\n",
    "#################\n",
    "# Aggregate tick data\n",
    "#################\n",
    "signal_mid_price_series = (signal_tick_data.loc[:, 'Bid0'] + signal_tick_data.loc[:, 'Offer0']) / 2\n",
    "trigger_mid_price_series = (trigger_tick_data.loc[:, 'Bid0'] + trigger_tick_data.loc[:, 'Offer0']) / 2\n",
    "reval_mid_price_series = (reval_tick_data.loc[:, 'Bid0'] + reval_tick_data.loc[:, 'Offer0']) / 2\n",
    "# print(reval_mid_price_series.tail())\n",
    "\n",
    "#################\n",
    "# HLOC\n",
    "#################\n",
    "signal_tick_data[\"mid\"] = (signal_tick_data.loc[:, 'Bid0'] + signal_tick_data.loc[:, 'Offer0']) / 2\n",
    "\n",
    "\n",
    "# adding bid and offer \n",
    "bid_sampler = signal_tick_data.loc[:, 'Bid0'].resample(resample_period)\n",
    "bid_hloc = bid_sampler.ohlc() \n",
    "\n",
    "offer_sampler = signal_tick_data.loc[:, 'Offer0'].resample(resample_period)\n",
    "offer_hloc = offer_sampler.ohlc() \n",
    "\n",
    "# original\n",
    "bar_sampler = trigger_mid_price_series.resample(resample_period)\n",
    "hloc = bar_sampler.ohlc() \n",
    "\n",
    "\n",
    "#################\n",
    "# Derived columns\n",
    "#################\n",
    "\n",
    "hloc[\"Bid\"] = bid_hloc[\"close\"] \n",
    "hloc[\"Ask\"] = offer_hloc[\"close\"]  # tidy up naming of ask/offer\n",
    "\n",
    "\n",
    "hloc['o_to_h'] = (hloc['high'] / hloc['open'] - 1)\n",
    "hloc['o_to_l'] = (hloc['low'] / hloc['open'] - 1)\n",
    "hloc['c_to_c'] = hloc['close'].pct_change()\n",
    "\n",
    "hloc['o_to_h_vol'] = hloc['o_to_h'].rolling(ma_samples).std()\n",
    "hloc['o_to_l_vol'] = hloc['o_to_l'].rolling(ma_samples).std()\n",
    "hloc['c_to_c_vol'] = hloc['c_to_c'].rolling(ma_samples).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Trigger check\n",
    "#################\n",
    "\n",
    "def mid_trigger_price (timestamp, where): \n",
    "    index = trigger_mid_price_series[timestamp : timestamp + timestamp.freq].where(where).dropna().first_valid_index()\n",
    "    if index == None :\n",
    "        return None\n",
    "    result = reval_mid_price_series.asof(index)\n",
    "#     print(result)\n",
    "    return result\n",
    "\n",
    "def trigger_check(row, high_trigger_col, low_trigger_col, high_side):\n",
    "    \n",
    "    triggers = [\n",
    "        ['High', mid_trigger_price(row.name, lambda price: price.gt(row[high_trigger_col])), \n",
    "                 +high_side, row[high_trigger_col]],\n",
    "        ['Low', mid_trigger_price(row.name, lambda price: price.lt(row[low_trigger_col])),\n",
    "                -high_side, row[low_trigger_col]]\n",
    "    ]\n",
    "    \n",
    "    triggers = [t for t in triggers if t[1] is not None]\n",
    "    \n",
    "    triggers.sort(key=lambda t : t[1])\n",
    "    \n",
    "    if not triggers:\n",
    "        return None\n",
    "    \n",
    "    return triggers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Breakout signals\n",
    "#################\n",
    "\n",
    "hloc['breakout_high_trigger'] = hloc['open'] * (1 + (breakout_sigma * (hloc['o_to_h_vol'].shift(1))))\n",
    "hloc['breakout_low_trigger'] = hloc['open'] * (1 - (breakout_sigma * (hloc['o_to_l_vol'].shift(1))))\n",
    "\n",
    "hloc['breakout_triggered'] = hloc.apply(lambda row: trigger_check(row, 'breakout_high_trigger', 'breakout_low_trigger', 1), axis=1)\n",
    "hloc['breakout_triggered'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Mean reversion signals\n",
    "#################\n",
    "\n",
    "hloc['6_hr_ma'] = hloc['close'].rolling(ma_samples).mean()\n",
    "# hloc['6_hr_ma_sig'] = np.where(hloc['close'].shift(1) > hloc['6_hr_ma'].shift(1), 1, -1)\n",
    "\n",
    "hloc['mr_high_trigger'] = hloc['6_hr_ma'] * (1 + (mr_sigma * (hloc['c_to_c_vol'].shift(1))))\n",
    "hloc['mr_low_trigger'] = hloc['6_hr_ma'] * (1 - (mr_sigma * (hloc['c_to_c_vol'].shift(1))))\n",
    "\n",
    "hloc['mr_triggered'] = hloc.apply(lambda row: trigger_check(row, 'mr_high_trigger', 'mr_low_trigger', -1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# position\n",
    "hloc_filtered = hloc\n",
    "hloc_filtered['breakout_trade'] = hloc_filtered['breakout_triggered'].map(lambda x: 0 if x is None else x[2])\n",
    "hloc_filtered['breakout_trade_price'] = hloc_filtered['breakout_triggered'].map(lambda x: 0 if x is None else x[1])\n",
    "hloc_filtered['breakout_contra_trade_amount'] = -1 * hloc_filtered['breakout_trade'] * hloc_filtered['breakout_trade_price']\n",
    "\n",
    "hloc_filtered['mr_trade'] = hloc_filtered['mr_triggered'].map(lambda x: 0 if x is None else x[2])\n",
    "hloc_filtered['mr_trade_price'] = hloc_filtered['mr_triggered'].map(lambda x: 0 if x is None else x[1])\n",
    "hloc_filtered['mr_contra_trade_amount'] = -1 * hloc_filtered['mr_trade'] * hloc_filtered['mr_trade_price']\n",
    "hloc_filtered['position'] = hloc_filtered['breakout_trade'].cumsum() + hloc_filtered['mr_trade'].cumsum()\n",
    "\n",
    "stdev = np.std(hloc_filtered['close'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hedge trades\n",
    "hloc_filtered['hedge_trade'] = 0.0\n",
    "hloc_filtered['hedge_price'] = 0.0\n",
    "hedge_trade_sum = 0.0\n",
    "hloc_filtered['hedge_contra_amount'] = 0.0\n",
    "current_position = 0.0\n",
    "keep_position = True\n",
    "i_prev = None\n",
    "n = len(hloc_filtered)\n",
    " \n",
    "for i in hloc_filtered.index:\n",
    "    stay_long, stay_short = False, False\n",
    "    current_position = hloc_filtered.loc[i]['position'] + hedge_trade_sum\n",
    "    \n",
    "    if(optimise_exit) :\n",
    "        if current_position > 0 and (hloc_filtered.loc[i]['close'] > (hloc_filtered.loc[i_prev]['close'] + 2.5 * stdev)):\n",
    "            stay_long = False\n",
    "        if current_position < 0 and (hloc_filtered.loc[i]['close'] < (hloc_filtered.loc[i_prev]['close'] - 2.5 * stdev)):\n",
    "            stay_short = False\n",
    "        keep_position = stay_long or stay_short\n",
    "    \n",
    "    if i_prev and not keep_position and (np.absolute(current_position) >= hedge_level):\n",
    "        hloc_filtered.loc[i,'hedge_trade'] = -1 * current_position\n",
    "        hedge_trade_sum += -1 * current_position\n",
    "        # TODO: Review\n",
    "        hedge_price = hloc_filtered.asof(i + pd.Timedelta(milliseconds=interest_to_fill),\n",
    "                                         subset=['close'])['close']\n",
    "        hloc_filtered.loc[i,'hedge_price'] = hedge_price\n",
    "        hloc_filtered.loc[i,'hedge_contra_amount'] = -1 * hloc_filtered.loc[i,'hedge_trade'] * \\\n",
    "                                                     hloc_filtered.loc[i,'hedge_price']\n",
    "    i_prev = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['hedge_balance'] = hloc_filtered['hedge_trade'].cumsum()\n",
    "hloc_filtered['overall_position'] = hloc_filtered['breakout_trade'].cumsum() + hloc_filtered['mr_trade'].cumsum() + hloc_filtered['hedge_trade'].cumsum()\n",
    "hloc_filtered['overall_contra_position'] = hloc_filtered['breakout_contra_trade_amount'].cumsum() + hloc_filtered['mr_contra_trade_amount'].cumsum() + hloc_filtered['hedge_contra_amount'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pnl\n",
    "hloc_filtered['pnl'] = np.where(hloc_filtered['overall_position'] == 0, hloc_filtered['overall_contra_position'], hloc_filtered['overall_position'] * hloc_filtered['close'] + hloc_filtered['overall_contra_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mr strategy returns\n",
    "hloc_filtered['pnl'].resample(\"10s\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['c_to_c_vol'].resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['overall_position'].resample(\"5s\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volumes, pnl and yield\n",
    "y = 0\n",
    "breakout_volume = np.abs(hloc_filtered['breakout_trade']).sum()\n",
    "mr_volume = np.abs(hloc_filtered['mr_trade']).sum()\n",
    "hedge_volume = np.abs(hloc_filtered['hedge_trade']).sum()\n",
    "total_volume = breakout_volume + mr_volume + hedge_volume\n",
    "total_pnl = hloc_filtered['pnl'].tail(1)\n",
    "y = total_pnl / total_volume \n",
    "display(breakout_volume, mr_volume, hedge_volume, total_volume, total_pnl, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhbo_position = 0\n",
    "maxPosition = 5\n",
    "\n",
    "for i in hloc_filtered.index:\n",
    "    trade = hloc_filtered.loc[i]['breakout_trade']\n",
    "    if(trade != 0) :\n",
    "        if abs(nhbo_position) < maxPosition:\n",
    "#             display(abs(nhbo_position))\n",
    "            hloc_filtered.loc[i, 'nhbo_trade'] = hloc_filtered['breakout_trade'].loc[i]\n",
    "            hloc_filtered.loc[i, 'nhbo_trade_price'] = hloc_filtered['breakout_trade_price'].loc[i]\n",
    "            hloc_filtered.loc[i, 'nhbo_contra_amount'] = hloc_filtered['breakout_contra_trade_amount'].loc[i]\n",
    "            nhbo_position = nhbo_position + hloc_filtered['breakout_trade'].loc[i]\n",
    "            \n",
    "        else :\n",
    "            hloc_filtered.loc[i, 'nhbo_trade'] = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hloc_filtered['nhbo_position'] = hloc_filtered['nhbo_trade'].cumsum()\n",
    "hloc_filtered['nhbo_contra_position'] = hloc_filtered['nhbo_contra_amount'].cumsum()\n",
    "\n",
    "hloc_filtered['nhbo_pnl'] = np.where(hloc_filtered['nhbo_position'] == 0, \n",
    "        hloc_filtered['nhbo_contra_position'], \n",
    "        hloc_filtered['nhbo_position'] * hloc_filtered['close'] + hloc_filtered['nhbo_contra_position'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Flow Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OFI lookback \n",
    "ofi_lookback = 50\n",
    "ofi_resample = \"10ms\"\n",
    "\n",
    "def ofi(quotes,level):\n",
    "    \"\"\"Returns Order Flow Imbalance for given levels of the orderbook\"\"\"\n",
    "    qdf = quotes.copy()\n",
    "    bid_price_label = 'Bid' + str(level)\n",
    "    offer_price_label = 'Offer' + str(level)\n",
    "    bid_qty_label = 'Bid' +str(level) + 'Qty'\n",
    "    offer_qty_label = 'Offer' + str(level)+'Qty'\n",
    "\n",
    "    qdf['prev_bidprice'] = qdf[bid_price_label].shift()\n",
    "    qdf['prev_bidsize'] = qdf[bid_qty_label].shift()\n",
    "    qdf['prev_askprice'] = qdf[offer_price_label].shift()\n",
    "    qdf['prev_asksize'] = qdf[offer_qty_label].shift()\n",
    "\n",
    "    # Fix any missing/invalid data\n",
    "    qdf.replace([np.inf, np.NINF], np.nan, inplace=True)\n",
    "    qdf.fillna(method=\"ffill\", inplace=True)\n",
    "    qdf.fillna(method=\"bfill\", inplace=True)\n",
    "    \n",
    "    bid_geq = qdf[bid_price_label] >= qdf['prev_bidprice']\n",
    "    bid_leq = qdf[bid_price_label] <= qdf['prev_bidprice']\n",
    "    ask_geq = qdf[offer_price_label] >= qdf['prev_askprice']\n",
    "    ask_leq = qdf[offer_price_label] <= qdf['prev_askprice']\n",
    "    \n",
    "    qdf['ofi'] = np.zeros(len(qdf))\n",
    "    qdf['ofi'].loc[bid_geq] += qdf[bid_qty_label].loc[bid_geq]\n",
    "    qdf['ofi'].loc[bid_leq] -= qdf['prev_bidsize'].loc[bid_leq]\n",
    "    qdf['ofi'].loc[ask_geq] += qdf['prev_asksize'].loc[ask_geq]\n",
    "    qdf['ofi'].loc[ask_leq] -= qdf[offer_qty_label].loc[ask_leq]    \n",
    "    return qdf['ofi']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# OFI using top x levels \n",
    "########################\n",
    "df_all = signal_tick_data.resample(ofi_resample).last().ffill()\n",
    "df_all = df_all\n",
    "\n",
    "df_all[\"Offer0Qty\"] = df_all[\"Offer0Qty\"].astype('float')\n",
    "df_all[\"Offer0\"] = df_all[\"Offer0\"].astype('float')\n",
    "df_all[\"Bid0\"] = df_all[\"Bid0\"].astype('float')\n",
    "df_all[\"Bid0Qty\"] = df_all[\"Bid0Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer1Qty\"] = df_all[\"Offer1Qty\"].astype('float')\n",
    "df_all[\"Offer1\"] = df_all[\"Offer1\"].astype('float')\n",
    "df_all[\"Bid1\"] = df_all[\"Bid1\"].astype('float')\n",
    "df_all[\"Bid1Qty\"] = df_all[\"Bid1Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer2Qty\"] = df_all[\"Offer2Qty\"].astype('float')\n",
    "df_all[\"Offer2\"] = df_all[\"Offer2\"].astype('float')\n",
    "df_all[\"Bid2\"] = df_all[\"Bid2\"].astype('float')\n",
    "df_all[\"Bid2Qty\"] = df_all[\"Bid2Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer3Qty\"] = df_all[\"Offer3Qty\"].astype('float')\n",
    "df_all[\"Offer3\"] = df_all[\"Offer3\"].astype('float')\n",
    "df_all[\"Bid3\"] = df_all[\"Bid3\"].astype('float')\n",
    "df_all[\"Bid3Qty\"] = df_all[\"Bid3Qty\"].astype('float')\n",
    "\n",
    "df_all[\"Offer4Qty\"] = df_all[\"Offer4Qty\"].astype('float')\n",
    "df_all[\"Offer4\"] = df_all[\"Offer4\"].astype('float')\n",
    "df_all[\"Bid4\"] = df_all[\"Bid4\"].astype('float')\n",
    "df_all[\"Bid4Qty\"] = df_all[\"Bid4Qty\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OFI with levels 1, 2 and 3 (works better than 0,1,2)\n",
    "# 100 period MA works well\n",
    "\n",
    "df_all = df_all #.resample(ofi_resample).last().ffill()\n",
    "df_all['ofi'] = ofi(df_all,1) + ofi(df_all,2) + ofi(df_all,3) \n",
    "\n",
    "df_all[\"ofi_rolling\"] = df_all['ofi'].rolling(ofi_lookback).mean()\n",
    "df_all['ofi_signal'] = np.where(df_all['ofi_rolling'] > 0, 1, -1)\n",
    "df_all['mid'] = ((df_all['Bid0'] + df_all['Offer0']) / 2.0)\n",
    "df_all['mid_change'] = ((df_all['Bid0'] + df_all['Offer0']) / 2.0).pct_change()\n",
    "\n",
    "\n",
    "# shift the signal\n",
    "df_all['ofi_signal'] = df_all['ofi_signal'].shift(1)\n",
    "df_all['ofi_pnl'] = (df_all['ofi_signal'] * df_all['mid_change'])\n",
    "\n",
    "print(\"Cumulative PnL \" + str(df_all['ofi_pnl'].cumsum().iloc[-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_pnl'].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Weighted Mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# Volume Weighted Mids\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CWM\n",
    "cwm_lookback = 2\n",
    "\n",
    "df_all['weighted_bid_notional_5'] =  df_all[\"Bid1Qty\"] + df_all[\"Bid2Qty\"] + df_all[\"Bid3Qty\"] + df_all[\"Bid4Qty\"]\n",
    "df_all['weighted_offer_notional_5'] =  df_all[\"Offer1Qty\"] + df_all[\"Offer2Qty\"] + df_all[\"Offer3Qty\"] + df_all[\"Offer4Qty\"]\n",
    "df_all['weighted_bid_5'] = (df_all[\"Bid1Qty\"] * df_all[\"Bid1\"] + df_all[\"Bid2Qty\"] * df_all[\"Bid2\"] + df_all[\"Bid3Qty\"] * df_all[\"Bid3\"] + df_all[\"Bid4Qty\"] * df_all[\"Bid4\"]) / df_all['weighted_bid_notional_5'] \n",
    "df_all['weighted_offer_5'] = ( df_all[\"Offer1Qty\"] * df_all[\"Offer1\"] + df_all[\"Offer2Qty\"] * df_all[\"Offer2\"] + df_all[\"Offer3Qty\"] * df_all[\"Offer3\"] + df_all[\"Offer4Qty\"] * df_all[\"Offer4\"]) / df_all['weighted_offer_notional_5'] \n",
    "df_all['conventionally_weighted_mid_5'] = (df_all['weighted_bid_5'] + df_all['weighted_offer_5']) / 2\n",
    "df_all['cwm'] = df_all['conventionally_weighted_mid_5']\n",
    "df_all['cwm_signal'] = np.where(df_all['cwm'] >= df_all['mid'], 1, -1)\n",
    "\n",
    "\n",
    "# slow down to XTX pace \n",
    "df_all['cwm_signal_slow'] = df_all['cwm_signal'].rolling(cwm_lookback).mean()\n",
    "\n",
    "\n",
    "# shift signal and calculate returns\n",
    "df_all['cwm_signal'] = df_all['cwm_signal_slow'].shift(1)\n",
    "df_all['cwm_pnl'] = df_all['cwm_signal'] * df_all['mid_change']\n",
    "df_all['cwm_pnl'].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VWM - level 1 \n",
    "df_all['vwm'] = (df_all[\"Bid1Qty\"] * df_all[\"Offer1\"] + df_all[\"Bid1\"] * df_all[\"Offer1Qty\"])  / (df_all[\"Bid1Qty\"] + df_all[\"Offer1Qty\"])\n",
    "df_all['vwm_signal'] = np.where(df_all['vwm'] >= df_all['mid'], 1, -1)\n",
    "\n",
    "df_all['vwm_signal'] = np.where(df_all['vwm'] > df_all['mid'], 1, -1)\n",
    "\n",
    "# shift the signal\n",
    "df_all['vwm_signal'] = df_all['vwm_signal'].shift(1)\n",
    "\n",
    "# calculate returns\n",
    "df_all['vwm_pnl'] = df_all['vwm_signal'] * df_all['mid_change']\n",
    "df_all['vwm_pnl'].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Trend Following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Trend and Crossover\n",
    "####################\n",
    "\n",
    "trend_lookback = 200\n",
    "\n",
    "crossover_1_lookback = 100\n",
    "crossover_2_lookback = 500\n",
    "\n",
    "# simple trend following model for mid generation\n",
    "df_all['trend_signal'] = np.where(df_all['mid'] > df_all['mid'].rolling(trend_lookback).mean(), 1, -1)\n",
    "df_all['trend_signal'] = df_all['trend_signal'].shift(1)\n",
    "df_all['trend_pnl'] = df_all['trend_signal'] * df_all['mid_change']\n",
    "\n",
    "# ma crossover\n",
    "df_all['crossover_signal'] = np.where(df_all['mid'].rolling(crossover_1_lookback).mean() > df_all['mid'].rolling(crossover_2_lookback).mean(), 1, -1)\n",
    "df_all['crossover_signal'] = df_all['crossover_signal'].shift(1)\n",
    "df_all['crossover_pnl'] = df_all['crossover_signal'] * df_all['mid_change']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['crossover_pnl', 'trend_pnl']].between_time('00:00', '22:00').cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['combined_signal'] = np.sign(df_all['ofi_signal'] + df_all['trend_signal'] + df_all['cwm_signal'])\n",
    "df_all['combined_pnl'] = df_all['mid_change'] * df_all['combined_signal']\n",
    "df_all['combined_pnl'].between_time('07:00', '19:00').cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 10ms breakout signal and combine with OFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout_signal = hloc_filtered['overall_position'].resample(ofi_resample).last().ffill()\n",
    "breakout_signal = np.sign(breakout_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakout_signal.resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"breakout_signal\"] = breakout_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"breakout_pnl\"] = df_all[\"breakout_signal\"] * df_all['mid_change']\n",
    "\n",
    "df_all[\"breakout_pnl\"].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt signal - Regime Switching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set adaptive lookback period\n",
    "adapt_rolling = 10000\n",
    "\n",
    "df_all['ofi_pnl_ma'] = df_all['ofi_pnl'].rolling(adapt_rolling).mean()\n",
    "df_all['trend_pnl_ma'] = df_all['trend_pnl'].rolling(adapt_rolling).mean()\n",
    "df_all['cwm_pnl_ma'] = df_all['cwm_pnl'].rolling(adapt_rolling).mean()\n",
    "df_all['breakout_pnl_ma'] = df_all['breakout_pnl'].rolling(adapt_rolling).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['combined_pnl_ma'] = (df_all['ofi_pnl_ma'] + df_all['trend_pnl_ma'] + df_all['breakout_pnl_ma']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ofi_weight'] = np.where(df_all['ofi_pnl_ma'] > 0, 1, 0)\n",
    "df_all['ofi_weight'] = df_all['ofi_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['trend_weight'] = np.where(df_all['trend_pnl_ma'] > 0, 1, 0)\n",
    "df_all['trend_weight'] = df_all['trend_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['cwm_weight'] = np.where(df_all['cwm_pnl_ma'] > 0, 1, 0)\n",
    "df_all['cwm_weight'] = df_all['cwm_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['breakout_weight'] = np.where(df_all['breakout_pnl_ma'] > 0, 1, 0)\n",
    "df_all['breakout_weight'] = df_all['breakout_weight'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two versions of the adapt\n",
    "\n",
    "# weighted by recent pnl\n",
    "df_all['adapt_signal'] = np.sign(\n",
    "    (df_all['cwm_weight'] * df_all['cwm_signal']) + \n",
    "    (df_all['trend_weight'] * df_all['trend_signal']) +\n",
    "    (df_all['ofi_weight'] * df_all['ofi_signal'])\n",
    ")\n",
    "\n",
    "# unweighted \n",
    "# df_all['adapt_signal'] = np.sign(\n",
    "#     df_all['breakout_signal'] +\n",
    "#     df_all['trend_signal'] +\n",
    "#     df_all['ofi_signal']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_pnl'] = df_all['mid_change'] * df_all['adapt_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['adapt_pnl'].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pnl Per Trade and Holding Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Counts the number of ticks between changes in the signal\n",
    "# Calculates pnl per trade \n",
    "###############\n",
    "\n",
    "# these are the df and column for the signals \n",
    "signal_df = df_all\n",
    "signal_column = 'breakout_signal'\n",
    "\n",
    "# the df and column for the pnl\n",
    "pnl_column = df_all['breakout_pnl']\n",
    "\n",
    "\n",
    "def SignalPersisenceFast(df,column_name): \n",
    "    array= df[column_name].values\n",
    "    previous_signal  = False \n",
    "    Counter = 0\n",
    "    Times = []\n",
    "    for x in range(len(array)):\n",
    "        if((array[x] == previous_signal or Counter == 0) and array[x] != 0):\n",
    "            Counter = Counter + 1\n",
    "        else:\n",
    "            Times.append(Counter)\n",
    "            if array[x] != 0 : \n",
    "                Counter =  1\n",
    "        previous_signal = array[x]\n",
    "    return Times\n",
    "\n",
    "Times = SignalPersisenceFast(df_all,signal_column)\n",
    "number_trades = (df_all[\"s\"].count() / np.mean(Times))\n",
    "pnl_per_trade = pnl_column.sum() / number_trades\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints out the results\n",
    "print(\"**configs**\")\n",
    "print(\"adapt rolling: \"f'{adapt_rolling:d}')\n",
    "print(\"trend lookback: \"f'{trend_lookback:.0f}')\n",
    "print(\"cwm lookback: \"f'{cwm_lookback:.0f}')\n",
    "print(\"ofi rolling: \"f'{ofi_lookback:.0f}')\n",
    "print(\"ofi resample ms: \"f'{ofi_resample}')\n",
    "print()\n",
    "\n",
    "print(\"**time in signal/trade**\")\n",
    "print(\"Mean units of time in trade \"f'{(np.mean(Times)):.2f}')\n",
    "print(\"25 percentile time in trade \" + str(np.percentile(Times, 25, axis=0)))\n",
    "print(\"Median time in trade \" + str(np.median(Times)))\n",
    "print(\"75 percentile time in trade \" + str(np.percentile(Times, 75, axis=0)))\n",
    "print()\n",
    "\n",
    "print(\"**performance stats**\")\n",
    "print(\"Number of signals/trades: \"f'{number_trades:.0f}')\n",
    "print(\"Cumulative PnL %: \"f'{(pnl_column.sum() * 100):.2f}')\n",
    "print(\"Average Trade PnL $ per million \"f'{(pnl_per_trade*1000000):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our mid \n",
    "inst_price_london = our_price.resample(ofi_resample).last().ffill()\n",
    "df_all[\"inst_ldn_bid\"] = inst_price_london[\"Bid0\"]\n",
    "df_all[\"inst_ldn_offer\"] = inst_price_london[\"Offer0\"]\n",
    "df_all[\"inst_ldn_mid\"] = (df_all[\"inst_ldn_bid\"] + df_all[\"inst_ldn_offer\"]) / 2\n",
    "df_all[\"inst_ldn_signal\"] = np.where(df_all[\"inst_ldn_mid\"] > df_all[\"mid\"], 1, -1)\n",
    "df_all[\"inst_ldn_signal\"] = df_all[\"inst_ldn_signal\"].shift(1)\n",
    "df_all[\"inst_ldn_pnl\"] = df_all[\"inst_ldn_signal\"] * df_all[\"mid_change\"]\n",
    "df_all[\"inst_ldn_pnl\"].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test XTX mids\n",
    "xtx_prices = xtx_prices.resample(ofi_resample).last().ffill()\n",
    "df_all[\"xtx_bid\"] = xtx_prices[\"Bid0\"]\n",
    "df_all[\"xtx_offer\"] = xtx_prices[\"Offer0\"]\n",
    "df_all[\"xtx_mid\"] = (df_all[\"xtx_bid\"] + df_all[\"xtx_offer\"]) / 2\n",
    "df_all[\"xtx_signal\"] = np.where(df_all[\"xtx_mid\"] > df_all[\"mid\"], 1, -1)\n",
    "df_all[\"xtx_signal\"] = df_all[\"xtx_signal\"].shift(1)\n",
    "df_all[\"xtx_pnl\"] = df_all[\"xtx_signal\"] * df_all[\"mid_change\"]\n",
    "df_all[[\"xtx_pnl\", \"combined_pnl\", \"inst_ldn_pnl\"]].cumsum().resample(\"1T\").last().plot()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run correlations between XTX and ourselves\n",
    "df_corr = df_all[[\"xtx_pnl\", \"adapt_pnl\", \"inst_ldn_pnl\", \"trend_pnl\", \"ofi_pnl\", \"cwm_pnl\", \"combined_pnl\"]]\n",
    "print(\"XTX correlation with: \"f'{df_corr.corr().iloc[:, 0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a regression to investigate XTX prices\n",
    "xtx_regression = df_corr\n",
    "\n",
    "import statsmodels.api as sm\n",
    "xtx_regression = xtx_regression.replace(np.NaN, 0)\n",
    "X = xtx_regression[[\"trend_pnl\", \"ofi_pnl\", \"cwm_pnl\"]]\n",
    "y = xtx_regression['xtx_pnl']\n",
    "## fit a OLS model with intercept on TV and Radio\n",
    "# X = sm.add_constant(X)\n",
    "est = sm.OLS(y, X).fit()\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old results\n",
    "\n",
    "# XTX mid as a predictor \n",
    "**time in signal/trade**\n",
    "Mean units of time in trade 115.23\n",
    "25 percentile time in trade 4.0\n",
    "Median time in trade 15.0\n",
    "75 percentile time in trade 103.0\n",
    "\n",
    "**performance stats**\n",
    "Number of signals/trades: 18745\n",
    "Cumulative PnL %: 12.75\n",
    "Average Trade PnL $ per million 6.80\n",
    "\n",
    "# our INST mid as a predictor \n",
    "**time in signal/trade**\n",
    "Mean units of time in trade 69.44\n",
    "25 percentile time in trade 3.0\n",
    "Median time in trade 7.0\n",
    "75 percentile time in trade 45.0\n",
    "\n",
    "**performance stats**\n",
    "Number of signals/trades: 31109\n",
    "Cumulative PnL %: 4.14\n",
    "Average Trade PnL $ per million 1.33\n",
    "\n",
    "# models - slow\n",
    "**time in signal/trade**\n",
    "Mean units of time in trade 255.59\n",
    "25 percentile time in trade 5.0\n",
    "Median time in trade 47.0\n",
    "75 percentile time in trade 360.0\n",
    "\n",
    "**performance stats**\n",
    "Number of signals/trades: 8452\n",
    "Cumulative PnL %: 4.69\n",
    "Average Trade PnL $ per million 5.55\n",
    "\n",
    "\n",
    "# models - faster\n",
    "**configs**\n",
    "adapt rolling: 10000\n",
    "trend lookback: 200\n",
    "cwm lookback: 5\n",
    "ofi rolling: 25\n",
    "ofi resample ms: 10ms\n",
    "\n",
    "**time in signal/trade**\n",
    "Mean units of time in trade 36.76\n",
    "25 percentile time in trade 7.0\n",
    "Median time in trade 25.0\n",
    "75 percentile time in trade 39.0\n",
    "\n",
    "**performance stats**\n",
    "Number of signals/trades: 58766\n",
    "Cumulative PnL %: 9.78\n",
    "Average Trade PnL $ per million 1.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_tick_data[[\"Bid0\", \"Offer0\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataframe\n",
    "\n",
    "# stores as class variables can be accessed in the strategy\n",
    "# e.g. df = [close, bid, offer, signal1, signal2, signal3]\n",
    "\n",
    "# set up high frequency trend following\n",
    "_hloc = hloc[[\"open\", \"high\", \"low\", \"close\", \"Bid\", \"Ask\"]] \n",
    "_hloc = _hloc.rename(columns={\"open\": \"Open\", \"high\": \"High\", \"low\": \"Low\", \"close\": \"Close\"})\n",
    "_hloc = _hloc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import backtesting library\n",
    "from backtesting import Backtest, Strategy\n",
    "from backtesting.lib import crossover\n",
    "\n",
    "def SMA(values, n):\n",
    "    \"\"\"\n",
    "    Return simple moving average of `values`, at\n",
    "    each step taking into account `n` previous values.\n",
    "    \"\"\"\n",
    "    return pd.Series(values).rolling(n).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting.lib import crossover\n",
    "\n",
    "class SmaCross(Strategy):\n",
    "    # Define the two MA lags as *class variables*\n",
    "    # for later optimization\n",
    "    n1 = 400\n",
    "    n2 = 500\n",
    "    \n",
    "    \n",
    "    def init(self):\n",
    "        # Precompute the two moving averages\n",
    "        self.sma1 = self.I(SMA, self.data.Close, self.n1)\n",
    "        self.sma2 = self.I(SMA, self.data.Close, self.n2)\n",
    "#         self.signal = self.data.Signal\n",
    "        # self.ask1 = self.data.Ask\n",
    "    \n",
    "    def next(self):\n",
    "        # If sma1 crosses above sma2, close any existing\n",
    "        # short trades, and buy \n",
    "        # if self.signal == 1:\n",
    "            \n",
    "        if crossover(self.sma1, self.sma2):\n",
    "            self.position.close()\n",
    "            self.buy()\n",
    "\n",
    "        # Else, if sma1 crosses below sma2, close any existing\n",
    "        # long trades, and sell \n",
    "        elif crossover(self.sma2, self.sma1):\n",
    "            self.position.close()\n",
    "            self.sell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script echo\n",
    "\n",
    "    def next(self):\n",
    "        if (self.sma1[-2] < self.sma2[-2] and\n",
    "                self.sma1[-1] > self.sma2[-1]):\n",
    "            self.position.close()\n",
    "            self.buy()\n",
    "\n",
    "        elif (self.sma1[-2] > self.sma2[-2] and    \n",
    "              self.sma1[-1] < self.sma2[-1]):\n",
    "            self.position.close()\n",
    "            self.sell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from backtesting import Backtest\n",
    "\n",
    "bt = Backtest(_hloc, SmaCross, cash=1_000_000, commission=.000, fee_rate = 0.00002)\n",
    "stats = bt.run()\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.plot(plot_volume=False, plot_pl=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = bt.optimize(n1=range(0, 500, 50),\n",
    "                    n2=range(0, 2000, 50),\n",
    "                    maximize='Equity Final [$]',\n",
    "                    constraint=lambda param: param.n1 < param.n2,\n",
    "                   )\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats._strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['_equity_curve']  # Contains equity/drawdown curves. DrawdownDuration is only defined at ends of DD periods.\n",
    "# plotly_line_chart(stats, \"Equity\", \"DrawdownPct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['_trades']  # Contains individual trade data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stats['_equity_curve'][[\"Equity\", \"DrawdownPct\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['_equity_curve'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(stats['_equity_curve'][\"Equity\"]).resample(\"D\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"return\"] = df[\"Equity\"].pct_change()\n",
    "daily_sharpe = (df[\"return\"].mean() * 365) / (df[\"return\"].std() * np.sqrt(365))\n",
    "print(f\"Daily Sharpe: \"{daily_sharpe})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Equity\"].plot(title=daily_sharpe);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Backtrader - return calculations. Bid-ask spread. Total spread paid. \n",
    "# Signal with and without spread. \n",
    "# Signal from other models. 1, 0, -1. \n",
    "# Return stats for intraday. \n",
    "\n",
    "# Walk forward each hour\n",
    "# Flip between MR and TF\n",
    "# Differentiate between short and long term TF\n",
    "# Cross market trend initiation? \n",
    "\n",
    "# AHL style with variance \n",
    "# Markov switching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EURUSD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting.test import SMA, EURUSD\n",
    "\n",
    "EURUSD[\"Bid\"] = EURUSD[\"Close\"]\n",
    "EURUSD[\"Ask\"] = EURUSD[\"Close\"]\n",
    "\n",
    "data = EURUSD.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BBANDS(data, n_lookback, n_std):\n",
    "\n",
    "    \"\"\"Bollinger bands indicator\"\"\"\n",
    "    hlc3 = (data.High + data.Low + data.Close) / 3\n",
    "    mean, std = hlc3.rolling(n_lookback).mean(), hlc3.rolling(n_lookback).std()\n",
    "    upper = mean + n_std*std\n",
    "    lower = mean - n_std*std\n",
    "    return upper, lower\n",
    "\n",
    "\n",
    "close = data.Close.values\n",
    "sma10 = SMA(data.Close, 10)\n",
    "sma20 = SMA(data.Close, 20)\n",
    "sma50 = SMA(data.Close, 50)\n",
    "sma100 = SMA(data.Close, 100)\n",
    "upper, lower = BBANDS(data, 20, 2)\n",
    "\n",
    "# Design matrix / independent features:\n",
    "\n",
    "# Price-derived features\n",
    "data['X_SMA10'] = (close - sma10) / close\n",
    "data['X_SMA20'] = (close - sma20) / close\n",
    "data['X_SMA50'] = (close - sma50) / close\n",
    "data['X_SMA100'] = (close - sma100) / close\n",
    "\n",
    "data['X_DELTA_SMA10'] = (sma10 - sma20) / close\n",
    "data['X_DELTA_SMA20'] = (sma20 - sma50) / close\n",
    "data['X_DELTA_SMA50'] = (sma50 - sma100) / close\n",
    "\n",
    "# Indicator features\n",
    "data['X_MOM'] = data.Close.pct_change(periods=2)\n",
    "data['X_BB_upper'] = (upper - close) / close\n",
    "data['X_BB_lower'] = (lower - close) / close\n",
    "data['X_BB_width'] = (upper - lower) / close\n",
    "data['X_Sentiment'] = ~data.index.to_series().between('2017-09-27', '2017-12-14')\n",
    "\n",
    "# Some datetime features for good measure\n",
    "data['X_day'] = data.index.dayofweek\n",
    "data['X_hour'] = data.index.hour\n",
    "\n",
    "data = data.dropna().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# need to set \n",
    "\n",
    "def get_X(data):\n",
    "    \"\"\"Return model design matrix X\"\"\"\n",
    "    return data.filter(like='X').values\n",
    "\n",
    "\n",
    "def get_y(data):\n",
    "    \"\"\"Return dependent variable y\"\"\"\n",
    "    y = data.Close.pct_change(48).shift(-48)  # Returns after 48 periods\n",
    "    y[y.between(-.004, .004)] = 0             # Devalue returns smaller than 0.04%\n",
    "    y[y > 0] = 1\n",
    "    y[y < 0] = -1\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_clean_Xy(df):\n",
    "    \"\"\"Return (X, y) cleaned of NaN values\"\"\"\n",
    "    X = get_X(df)\n",
    "    y = get_y(df).values\n",
    "    isnan = np.isnan(y)\n",
    "    X = X[~isnan]\n",
    "    y = y[~isnan]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = get_clean_Xy(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0)\n",
    "\n",
    "clf = KNeighborsClassifier(7)  # Model the output based on 7 \"nearest\" examples\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "_ = pd.DataFrame({'y_true': y_test, 'y_pred': y_pred}).plot(figsize=(15, 2), alpha=.7)\n",
    "print('Classification accuracy: ', np.mean(y_test == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from backtesting import Backtest, Strategy\n",
    "\n",
    "N_TRAIN = 400\n",
    "\n",
    "\n",
    "class MLTrainOnceStrategy(Strategy):\n",
    "    price_delta = .004  # 0.4%\n",
    "\n",
    "    def init(self):        \n",
    "        # Init our model, a kNN classifier\n",
    "        self.clf = KNeighborsClassifier(7)\n",
    "\n",
    "        # Train the classifier in advance on the first N_TRAIN examples\n",
    "        df = self.data.df.iloc[:N_TRAIN]\n",
    "        X, y = get_clean_Xy(df)\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "        # Plot y for inspection\n",
    "        self.I(get_y, self.data.df, name='y_true')\n",
    "\n",
    "        # Prepare empty, all-NaN forecast indicator\n",
    "        self.forecasts = self.I(lambda: np.repeat(np.nan, len(self.data)), name='forecast')\n",
    "\n",
    "    def next(self):\n",
    "        # Skip the training, in-sample data\n",
    "        if len(self.data) < N_TRAIN:\n",
    "            return\n",
    "\n",
    "        # Proceed only with out-of-sample data. Prepare some variables\n",
    "        high, low, close = self.data.High, self.data.Low, self.data.Close\n",
    "        current_time = self.data.index[-1]\n",
    "\n",
    "        # Forecast the next movement\n",
    "        X = get_X(self.data.df.iloc[-1:])\n",
    "        forecast = self.clf.predict(X)[0]\n",
    "\n",
    "        # Update the plotted \"forecast\" indicator\n",
    "        self.forecasts[-1] = forecast\n",
    "\n",
    "        # If our forecast is upwards and we don't already hold a long position\n",
    "        # place a long order for 20% of available account equity. Vice versa for short.\n",
    "        # Also set target take-profit and stop-loss prices to be one price_delta\n",
    "        # away from the current closing price.\n",
    "        upper, lower = close[-1] * (1 + np.r_[1, -1]*self.price_delta)\n",
    "\n",
    "        if forecast == 1 and not self.position.is_long:\n",
    "            self.buy(size=.2, tp=upper, sl=lower)\n",
    "        elif forecast == -1 and not self.position.is_short:\n",
    "            self.sell(size=.2, tp=lower, sl=upper)\n",
    "\n",
    "        # Additionally, set aggressive stop-loss on trades that have been open \n",
    "        # for more than two days\n",
    "        for trade in self.trades:\n",
    "            if current_time - trade.entry_time > pd.Timedelta('2 days'):\n",
    "                if trade.is_long:\n",
    "                    trade.sl = max(trade.sl, low)\n",
    "                else:\n",
    "                    trade.sl = min(trade.sl, high)\n",
    "\n",
    "\n",
    "bt = Backtest(data, MLTrainOnceStrategy, commission=.000001, margin=.05)\n",
    "bt.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "class MLWalkForwardStrategy(MLTrainOnceStrategy):\n",
    "    def next(self):\n",
    "        # Skip the cold start period with too few values available\n",
    "        if len(self.data) < N_TRAIN:\n",
    "            return\n",
    "\n",
    "        # Re-train the model only every 20 iterations.\n",
    "        # Since 20 << N_TRAIN, we don't lose much in terms of\n",
    "        # \"recent training examples\", but the speed-up is significant!\n",
    "        if len(self.data) % 20:\n",
    "            return super().next()\n",
    "\n",
    "        # Retrain on last N_TRAIN values\n",
    "        df = self.data.df[-N_TRAIN:]\n",
    "        X, y = get_clean_Xy(df)\n",
    "        self.clf.fit(X, y)\n",
    "\n",
    "        # Now that the model is fitted, \n",
    "        # proceed the same as in MLTrainOnceStrategy\n",
    "        super().next()\n",
    "\n",
    "\n",
    "bt = Backtest(data, MLWalkForwardStrategy, commission=.00001, margin=.05)\n",
    "bt.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
